### Infinite Hidden Markov Model for clustering together tree nodes generated by Random Forests

import numpy as np
import random
# import pymc3 as pm
from functools import reduce
from scipy.misc import comb as nCk
from tree_reader import Node as TreeReaderNode

from itertools import repeat

from scipy.special import logit,expit
from scipy.special import gamma as gamma_f

import multiprocessing as mp

import matplotlib.pyplot as plt

import pickle


## This model contains several interdependent variables:

##  - Hidden state sequence for nodes
##  - Transition probablities between hidden states
##  - Probability of any given sample emitting 0 or 1 when in a given state
##  - Hyperparameters governing the generative mechanism of the states

## These variables are sampled sequentially

class IHMM():
    def __init__(self,forest,alpha=1,beta=1,gamma=1,alpha_e=.5,beta_e=.5,start_states=20,inf_check=False,p=None,hierarchal=True):

        self.pool = mp.Pool(p)

        self.inf_check = inf_check
        self.hierarchal = hierarchal

        self.forest = forest

        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma

        self.alpha_e = alpha_e
        self.beta_e = beta_e

        self.hidden_states = start_states

        self.nodes = forest.nodes()
        self.live_nodes = forest.roots() + forest.stems()
        self.live_mask = np.zeros(len(self.nodes),dtype=bool)

        for node in self.live_nodes:
            self.live_mask[node.index] = True

        self.total_samples = len(forest.samples)
        self.total_nodes = len(self.nodes)

        self.node_states = np.zeros(self.total_nodes,dtype=int)

        self.child_index_l = np.zeros(self.total_nodes,dtype=int)
        self.child_index_r = np.zeros(self.total_nodes,dtype=int)
        self.child_state_l = np.zeros(self.total_nodes,dtype=int)
        self.child_state_r = np.zeros(self.total_nodes,dtype=int)

        for node in self.live_nodes:
            self.child_index_l[node.index] = node.children[0].index
            self.child_index_r[node.index] = node.children[1].index

        self.node_samples = forest.node_sample_encoding(self.nodes)

        self.divergence_l = np.zeros((self.total_nodes,self.total_samples),dtype=bool)
        self.divergence_r = np.zeros((self.total_nodes,self.total_samples),dtype=bool)

        for node in self.live_nodes:
            l,r = node.lr_encoding_vectors()
            self.divergence_l[node.index] = l
            self.divergence_r[node.index] = r

        for node in self.live_nodes:
            self.node_states[node.index] = random.randint(1,self.hidden_states-1)

        self.oracle_indicator_l = np.random.rand(self.total_nodes) < .5
        # self.oracle_indicator_l = np.random.rand(self.total_nodes) < 1/self.hidden_states
        # self.oracle_indicator_l = np.ones(self.total_nodes,dtype=bool)
        self.oracle_indicator_l[np.logical_not(self.live_mask)] = False

        self.oracle_indicator_r = np.random.rand(self.total_nodes) < .5
        # self.oracle_indicator_r = np.random.rand(self.total_nodes) < 1/self.hidden_states
        # self.oracle_indicator_r = np.ones(self.total_nodes,dtype=bool)
        self.oracle_indicator_r[np.logical_not(self.live_mask)] = False

        self.state_masks = np.zeros((self.hidden_states,self.total_nodes),dtype=bool)

        self.state_sample_log_odds = np.zeros((self.hidden_states,self.total_samples,3))


    ## Here we begin the methods for updating the state of the model over many "sweeps"

    ## Things that stay constant:
    ## Divergence masks
    ##    - These are the emissions of 0 or 1 per sample for a given node
    ## Number of samples
    ## Number of nodes
    ## State of nodes that aren't live or marked as null state
    ##    - These nodes don't have a divergence (probably because they're leaves), so they can't be modeled
    ## Node sample encoding
    ## Node relations (eg child indices)
    ##    -  Topology of the forest remains constant, we're only trying to learn it

    ## Things that update:
    ## Node states for live nodes
    ## Number of states
    ## Log odds of a sample emitting "1" vs "0" in a state
    ## Number of transitions between states
    ## State of children
    ## Hyperparameters

    ## Dependence flow:

    ## Node state gives gives=>
    ##  - Number of hidden states
    ##  - State masks

    ## - Number of states + masks + oracle transition indicator =>
    ##  - Transitions
    ##  - Oracle transitions
    ##  - State sample log odds

    ## - Transitions + number of states =>
    ##  - Transition log odds

    ## - Oracle indicator + Transitions =>
    ##  - MAP Hyperparameters

    ###### HERE WE BEGIN TO RECOMPUTE THE NODE STATE ####

    ## - Transition log odds + state sample log odds =>
    ##  - Log odds of direct state transitions per node
    ##  - Log odds of oracle per node

    ####### HERE WE DO THE FIRST SAMPLING STEP ##########

    ## - Oracle indicator + oracle log odds =>
    ##  - Log odds given oracle
    ##  - Log odds of secondary oracle

    ################ SECOND SAMPLING STEP ###############

    ##  - New states discovered
    ##  - Loop back to recomputing transitions & hypers

    def establish_parameters(self):

        ## This method establishes descriptive parameters given some sequence of hidden states over the node sequences.

        print(self.hidden_states)
        print(self.node_states)
        print(list(np.sum(self.state_masks,axis=1)))


        ### Here we re-assign hidden states to cleaned up indecies, in order to eliminate hidden states that no longer exist

        self.node_states = self.clean_state_indeces(self.node_states)

        ## Here we update the states assigned to the children of each node, this is setup to count the transition frequencies

        self.update_node_relations()

        ## State masks are a more conveninet way of storing which nodes belong to which states. They are numpy boolean mask arrays

        self.state_masks = self.recompute_state_masks(self.node_states)

        ## Here we compute the state log odds of emission for each sample for each state given the node assignments above

        self.state_sample_log_odds,self.state_raw_emission_counts,self.state_flips = self.recompute_state_sample_log_odds(self.hidden_states,self.total_nodes,self.total_samples,self.alpha_e,self.beta_e,self.state_masks,self.state_sample_log_odds,self.divergence_l,self.divergence_r)

        ## We would like to pad this matrix with the log odds of the oracle state. For it, we will use the log odds of all samples without partitioning

        # background_sample_log_odds = self.compute_background_divergence_odds(self.alpha_e,self.beta_e,self.divergence_l,self.divergence_r)
        background_sample_log_odds = np.zeros((1,self.total_samples,3))

        self.state_sample_log_odds = np.concatenate((self.state_sample_log_odds,background_sample_log_odds),axis=0)

        ## And here we count the transition counts

        self.transition_counts = self.recompute_transition_counts(self.live_mask,self.oracle_indicator_l,self.oracle_indicator_r,self.hidden_states,self.node_states,self.child_state_l,self.child_state_r)

        ## Here we count which transitions occurred through an oracle in order to recalculate the oracle transition frequencies

        self.oracle_transition_matrix = self.recompute_oracle_transition_matrix(self.hidden_states,self.oracle_indicator_l,self.oracle_indicator_r,self.node_states,self.child_state_l,self.child_state_r)
        self.oracle_transition_counts = self.recompute_oracle_transition_counts(self.oracle_transition_matrix)

        ## And finally here, on the basis of how often the oracle was used and the number of observed states, we sample the hyperparameters

        self.sample_hypers()


    def sweep(self):

        print("Sweep")

        if not self.hierarchal:
            self.transition_counts = np.ones(self.transition_counts.shape) * ((np.sum(oracle_transition_counts) / self.hidden_states) + 1)

        self.establish_parameters()

        if not self.hierarchal:
            self.transition_counts = np.ones(self.transition_counts.shape) * ((np.sum(oracle_transition_counts) / self.hidden_states) + 1)

        ### The above methods establish a description of the current state.

        ### The methods below establish the log odds of each given state for each given node, and whether an oracle was used to reach it

        new_node_states = np.zeros(self.total_nodes,dtype=int)
        new_state_indicator = np.zeros(self.total_nodes,dtype=bool)
        new_oracle_indicator = np.zeros(self.total_nodes,dtype=bool)

        ## First we establish the log odds of a given state based on the divergence observed

        self.state_log_odds_given_divergence = self.compute_state_log_odds_given_divergence(self.divergence_l,self.divergence_r,self.state_flips,self.node_states,self.state_sample_log_odds)

        # self.state_log_odds_given_divergence = self.state_log_odds_given_divergence / self.hidden_states

        ## This matrix contains only odds of existing states based on divergence, eg it is hidden_states x nodes in dimension, plus an extra row for a novel state

        if self.inf_check:
            print("Divergence odds")
            print(list(self.state_log_odds_given_divergence))
            if np.isnan(self.state_log_odds_given_divergence).any():
                raise Exception("NaN state log odds given divergence")
            if np.isinf(self.state_log_odds_given_divergence).any():
                raise Exception("Inf state log odds given divergence")

        #### IMPORTANT ####

        ## This next section works with raw odds because there is a need to add together the odds of a state given oracle and given no oracle_mask

        #### DO NOT MIX ODDS AND LOG ODDS, BAD ####

        ## Next we establish the odds of a given state or the oracle given its children

        self.direct_state_odds_given_child_l = self.compute_state_odds_given_child_direct_transition(self.beta,self.transition_counts,self.node_states,self.child_state_l)
        self.direct_state_odds_given_child_r = self.compute_state_odds_given_child_direct_transition(self.beta,self.transition_counts,self.node_states,self.child_state_r)

        ## We extract the odds of visiting the oracle for each given node and tile them

        self.oracle_odds_given_child_l = np.tile(self.direct_state_odds_given_child_l[-1],(self.hidden_states + 1,1))
        self.oracle_odds_given_child_r = np.tile(self.direct_state_odds_given_child_r[-1],(self.hidden_states + 1,1))

        if self.inf_check:
            print(list(self.direct_state_odds_given_child_l))
            print(list(self.direct_state_odds_given_child_r))
            if np.isnan(self.oracle_odds_given_child_l[:,self.live_mask]).any():
                raise Exception("NaN oracle odds")
            if np.isnan(self.oracle_odds_given_child_r[:,self.live_mask]).any():
                raise Exception("NaN oracle odds")

            if np.isinf(self.oracle_odds_given_child_l[:,self.live_mask]).any():
                raise Exception("Inf oracle odds")
            if np.isinf(self.oracle_odds_given_child_r[:,self.live_mask]).any():
                raise Exception("Inf oracle odds")


            if (np.sum(self.direct_state_odds_given_child_l,axis=0) == 0).any():
                raise Exception("Total zero transition odds")
            if (np.sum(self.direct_state_odds_given_child_r,axis=0) == 0).any():
                raise Exception("Total zero transition odds")



        # print("ORACLE_ODDS_DEBUG")
        # print(self.oracle_odds_given_child_l.shape)
        # print(self.oracle_odds_given_child_r.shape)

        ### THIS IS IMPORTANT ###
        ## We NOW set the bottom rows to zero, so that it will be filled in with the odds of a novel state momentarily
        self.direct_state_odds_given_child_l[-1] = 0
        self.direct_state_odds_given_child_r[-1] = 0

        if self.inf_check:
            if np.isnan(self.direct_state_odds_given_child_l[:,self.live_mask]).any():
                raise Exception("NaN direct state odds")
            if np.isnan(self.direct_state_odds_given_child_r[:,self.live_mask]).any():
                raise Exception("NaN direct state odds")
            if np.isinf(self.direct_state_odds_given_child_l[:,self.live_mask]).any():
                raise Exception("Inf direct state odds")
            if np.isinf(self.direct_state_odds_given_child_r[:,self.live_mask]).any():
                raise Exception("Inf direct state odds")

        ## Next we need to establish the odds of a given state given that an oracle was visited
        ## These are tiled across every node because they are uniform

        self.oracle_odds = self.compute_state_odds_given_oracle(self.gamma,self.total_nodes,self.oracle_transition_counts)

        if self.inf_check:
            print(list(self.oracle_odds))
            if np.isnan(self.oracle_odds[:,self.live_mask]).any():
                raise Exception("NaN oracle odds")
            if np.isinf(self.oracle_odds[:,self.live_mask]).any():
                raise Exception("Inf oracle odds")


        ## Next we get the odds of obtaining each state by the oracle route through multiplication:

        self.state_odds_given_oracle_l = self.oracle_odds_given_child_l * self.oracle_odds
        self.state_odds_given_oracle_r = self.oracle_odds_given_child_r * self.oracle_odds

        if self.inf_check:
            if np.isnan(self.state_odds_given_oracle_l[:,self.live_mask]).any():
                mask = np.logical_and(np.sum(np.isnan(self.state_odds_given_oracle_l),axis=0) > 0,self.live_mask)
                print("Total Odds")
                print(list(self.state_odds_given_oracle_l[:,mask]))
                print("Direct Odds")
                print(list(self.direct_state_odds_given_child_l[:,mask]))
                print(list(self.direct_state_odds_given_child_r[:,mask]))
                print("Odds of Oracle")
                print(list(self.oracle_odds_given_child_l[:,mask]))
                print(list(self.oracle_odds_given_child_r[:,mask]))
                print("Oracle odds")
                print(list(self.oracle_odds[:,mask]))
                raise Exception("NaN state odds given oracle")
            if np.isinf(self.state_odds_given_oracle_l[:,self.live_mask]).any():
                raise Exception("Inf state odds given oracle")
            if np.isnan(self.state_odds_given_oracle_r[:,self.live_mask]).any():
                raise Exception("NaN state odds given oracle")
            if np.isinf(self.state_odds_given_oracle_r[:,self.live_mask]).any():
                raise Exception("Inf state odds given oracle")



        # print("ORACLE_ODDS_DEBUG2")
        # print(self.state_odds_given_oracle_l.shape)
        # print(self.state_odds_given_oracle_r.shape)

        ## Finally we combine the odds and transform them into log form
        ## NOTE the final row is now the odds of a novel state, because it is the odds of visiting the oracle multiplied by the odds of obtaining a new state from the oracle

        self.state_odds_given_child_l = self.direct_state_odds_given_child_l + self.state_odds_given_oracle_l
        self.state_odds_given_child_r = self.direct_state_odds_given_child_r + self.state_odds_given_oracle_r

        if self.inf_check:
            if np.isnan(self.state_odds_given_child_l[:,self.live_mask]).any():
                raise Exception("NaN child state odds")
            if np.isnan(self.state_odds_given_child_r[:,self.live_mask]).any():
                raise Exception("NaN child state odds")

            if (self.state_odds_given_child_l < 0).any():
                raise Exception("Negative odds!")
            if (self.state_odds_given_child_r < 0).any():
                raise Exception("Negative odds!")

        ## And here we transform the plain odds into log odds:

        self.state_log_odds_given_child_l = np.log2(self.state_odds_given_child_l)
        self.state_log_odds_given_child_r = np.log2(self.state_odds_given_child_r)

        if self.inf_check:
            if np.isnan(self.state_log_odds_given_child_l[1:,self.live_mask]).any():
                raise Exception("NaN child state log odds")
            if np.isnan(self.state_log_odds_given_child_r[1:,self.live_mask]).any():
                raise Exception("NaN child state log odds")
            if np.isinf(self.state_log_odds_given_child_l[1:,self.live_mask]).any():
                raise Exception("Inf child state log odds")
            if np.isinf(self.state_log_odds_given_child_r[1:,self.live_mask]).any():
                raise Exception("Inf child state log odds")


        #THIS IS A TEMPORARY HACK FOR AN UNSTRUCTURED DP MIXTURE MODEL:
        # self.state_log_odds_given_child_l = np.log2(self.oracle_odds)
        # self.state_log_odds_given_child_r = np.log2(self.oracle_odds)
        #TEMP HACK ENDS HERE

        ## Finally we want to combine all log odds and sample the resulting distribution

        self.state_log_odds = self.state_log_odds_given_divergence + self.state_log_odds_given_child_l + self.state_log_odds_given_child_r

        if self.inf_check:
            if np.isnan(self.state_log_odds[1:,self.live_mask]).any():
                raise Exception("NaN additive log state odds")
            if np.isinf(self.state_log_odds[1:,self.live_mask]).any():
                raise Exception("Inf additive log state odds")

        new_node_states[self.live_mask],new_state_indicator[self.live_mask] = self.sample_states(self.live_mask,self.state_log_odds)

        new_oracle_indicator_l,new_oracle_indicator_r = self.sample_oracle_indicator(new_node_states,self.live_mask,self.direct_state_odds_given_child_l,self.direct_state_odds_given_child_r,self.state_odds_given_oracle_l,self.state_odds_given_oracle_r)

        new_oracle_indicator_l[new_state_indicator] = True
        new_oracle_indicator_r[new_state_indicator] = True

        total_new_states = np.sum(new_state_indicator)

        # print("New states created:")
        # print(total_new_states)
        # new_node_states[new_state_indicator] = np.arange(self.hidden_states, self.hidden_states + total_new_states)

        print("New state created")
        print(total_new_states)

        self.node_states = new_node_states
        self.oracle_indicator_l = new_oracle_indicator_l
        self.oracle_indicator_r = new_oracle_indicator_r

    def max_likelihood_sweep(self):

        ## This sweep assigns nodes to their most likely state, not a state sampled at random.

        self.sweep()
        new_node_states = np.zeros(self.node_states.shape[0])
        new_node_states[self.live_mask] = np.argmax(self.state_log_odds[:,self.live_mask],axis=0)
        self.node_states = new_node_states
        self.establish_parameters()


    def sample_hypers(self):


        print("Sampling Hypers")
        # print(f"Beta:{self.beta}")
        # print(f"Gamma:{self.gamma}")

        self.beta = self.recompute_beta()
        self.gamma = self.recompute_gamma()

        print(f"Beta:{self.beta}")
        print(f"Gamma:{self.gamma}")


    def recompute_beta(self):

        ## Here we compute the maximum a-posteriori probability for the beta parameter
        ## Due to falling factorials in the formula, we will want to use a stirling approximation,
        ## For this it is convenient to pre-compute a series of logs of integers

        ## The likelihood of beta is given by: beta ^ (k-1) / (sum of all non-oracle transitions)

        k = self.hidden_states

        transition_matrix = self.transition_counts + self.oracle_transition_matrix

        sums = np.sum(transition_matrix,axis=1)

        # max_sum = int(np.sum(sums) * 2)
        max_sum = int(np.max(sums) * 2)

        log_sequence = np.log2(np.arange(1,max_sum*2))

        likelihood_sequence = np.zeros(max_sum)[1:]

        for i,transitions in enumerate(transition_matrix):
            transitions = self.transition_counts[i]
            # total = np.sum(transitions)
            total = int(sums[i])
            non_zero = int(np.sum(transitions > 0))
            l2ls = lambda b: (non_zero * np.log2(b)) - np.sum(log_sequence[b:total+b])
            likelihood_sequence += np.array([l2ls(b) for b in range(1,max_sum)])

        likelihood_sequence -= log_sequence[:len(likelihood_sequence)]

        beta = np.argmax(likelihood_sequence) + 1

        return beta

    def recompute_gamma(self,max_gamma=None):

        k = self.hidden_states - 1

        oracle_total = int(np.sum(self.oracle_transition_counts))

        if max_gamma is None:

            max_gamma = oracle_total + 1

        log_sequence = np.log2(np.arange(1,max_gamma*2))

        # l2l = lambda g: ((k * np.log2(g)) - (np.sum(log_sequence[g+1:oracle_total+g+1]) + (g * 1.44)))
        l2l = lambda g: ((k * np.log2(g)) - (np.sum(log_sequence[g+1:oracle_total+g+1]) + np.log2(g)))

        likelihood_sequence = np.array([l2l(g) for g in range(1,max_gamma)])

        gamma = np.argmax(likelihood_sequence)+1

        # print("GAMMA DEBUG")
        # print(len(likelihood_sequence))
        # print(gamma)
        # print(max_gamma)
        # print(oracle_total)
        # print(likelihood_sequence[:50])
        # print("Alleged maximum likelihood")
        # print(likelihood_sequence[gamma-1])

        if (gamma + 1 == max_gamma) and max_gamma < self.total_nodes * 100:
            gamma = self.recompute_gamma(max_gamma = max_gamma * 5)

        return gamma

    def update_node_relations(self):

        self.child_state_l[self.live_mask] = self.node_states[self.child_index_l][self.live_mask]
        self.child_state_r[self.live_mask] = self.node_states[self.child_index_r][self.live_mask]

    def clean_state_indeces(self,node_states):

        print("State Index Cleanup")
        new_states = sorted(list(set(node_states)))
        print(new_states)
        new_indices = {old_index:i for i,old_index in enumerate(new_states)}
        print(new_indices)

        new_state_sequence = np.zeros(node_states.shape,dtype=int)

        for i,old_state in enumerate(node_states):
            new_state_sequence[i] = new_indices[old_state]

        self.hidden_states = len(new_states)

        # print(self.hidden_states)

        new_state_sample_log_odds = np.zeros((self.hidden_states,self.total_samples,3))

        for old_index,state in enumerate(self.state_sample_log_odds):
            if old_index in new_indices:
                new_state_sample_log_odds[new_indices[old_index]] = state

        self.state_sample_log_odds = new_state_sample_log_odds

        # print(new_state_sequence)

        return new_state_sequence

    def recompute_state_masks(self,node_states):

        print("Computing State Masks")

        new_states = self.hidden_states

        new_state_masks = np.zeros((new_states,node_states.shape[0]),dtype=bool)

        for state in range(new_states):
            new_state_masks[state] = node_states == state

        # print(new_state_masks.shape)

        if np.sum(self.node_states[self.live_mask] == 0) > 0:
            raise Exception()

        return new_state_masks


    def recompute_state_sample_log_odds(self,states,nodes,samples,alpha_e,beta_e,state_masks,state_sample_log_odds,divergence_l,divergence_r):

        print("Recomputing Sample Log Odds")

        # new_state_sample_log_odds_l = np.zeros((states,samples))
        # new_state_sample_log_odds_c = np.zeros((states,samples))
        # new_state_sample_log_odds_r = np.zeros((states,samples))
        new_state_sample_log_odds = np.zeros((states,samples,3))

        state_flips = np.zeros((states,nodes),dtype=bool)

        new_raw_emission_counts = np.zeros((states,samples,2))

        sample_totals = np.sum(divergence_l,axis=0) + np.sum(divergence_r,axis=0)

        sample_totals = sample_totals.astype(dtype=float)

        print(new_state_sample_log_odds.shape)

        for i,state_mask in list(enumerate(state_masks))[1:]:

            # print("SAMPLE LOG ODDS DEBUG")
            # print(state_mask.shape)
            # print(divergence_l.shape)

            ## First we want:
            ##  -only nodes in state
            ##  -left and right mask each
            ##      -This matrix is node x sample, true if left/right

            l = divergence_l[state_mask]
            r = divergence_r[state_mask]

            # print(l.shape)
            # print(r.shape)

            # print(i)
            # print(l.shape)
            # print(r.shape)

            ## We want to figure out whether to use the right or the left split of the node:

            ## First take each sample mask and use it to select log odds from state sample log odds

            state_sample_log_tile = np.tile(state_sample_log_odds[i,:,1],(np.sum(state_mask),1))

            # print("TILE DEBUG")
            # print(state_sample_log_tile.shape)
            # print(l.shape)

            ## Here we created a mask with dimensions of # of nodes in state x samples

            left_log_odds = np.zeros(l.shape)
            left_log_odds[l] = state_sample_log_tile[l]

            right_log_odds = np.zeros(r.shape)
            right_log_odds[r] = state_sample_log_tile[r]

            ## Next we sum the log odds to obtain total log odds of the fit of each side of the divergence
            ## to the state model

            ## Recall that each state model models the odds of a sample going left.

            left_fit = np.sum(left_log_odds,axis=1)
            right_fit = np.sum(right_log_odds,axis=1)

            ## If right fit is better than left fit, we would like to flip

            flip = right_fit > left_fit

            ## Next we want to figure out the totals going left and right

            l_total = np.sum(l[np.logical_not(flip)],axis=0) + np.sum(r[flip],axis=0)
            r_total = np.sum(r[np.logical_not(flip)],axis=0) + np.sum(l[flip],axis=0)

            ## L total here is a sample x 1 matrix that is the sum of all nodes present in the state that also had that sample go left
            ## R total here is a sample x 1 matrix that had the samples go the other way

            # print(l_total.shape)
            # print(r_total.shape)

            l_total = l_total.astype(dtype=float)
            r_total = r_total.astype(dtype=float)

            state_total = l_total + r_total

            ## Now one last trick remains: we have to pre-compute the odds if a node is removed from this state during evaluation
            ## This will allow us to compute a gibbs sweep in which a node is being evaluated that initially belonged to this state
            ##

            l_total_m = l_total - 1
            r_total_m = r_total - 1
            state_total_m = state_total - 1

            l_total_m[l_total_m < 0] = 0
            r_total_m[r_total_m < 0] = 0

            ## The new log odds are now ready to be computed:

            # new_state_sample_log_odds[i,:,0] = np.log2((l_total_m + alpha_e) / (r_total + beta_e))
            # new_state_sample_log_odds[i,:,1] = np.log2((l_total + alpha_e) / (r_total + beta_e))
            # new_state_sample_log_odds[i,:,2] = np.log2((l_total + alpha_e) / (r_total_m + beta_e))
            #
            # new_raw_emission_counts[i,:,0] = l_total
            # new_raw_emission_counts[i,:,1] = r_total
            #
            # state_flips[i][state_mask] = flip

            external = sample_totals - (l_total + r_total)

            if (external < 0).any():
                mask = external < 1
                print(sample_totals[mask])
                print(l_total[mask])
                print(r_total[mask])
                raise Exception()

            external_p = external + 1

            new_state_sample_log_odds[i,:,0] = np.log2((l_total_m + external_p + alpha_e) / (r_total + external_p + beta_e))
            new_state_sample_log_odds[i,:,1] = np.log2((l_total + external + alpha_e) / (r_total + external + beta_e))
            new_state_sample_log_odds[i,:,2] = np.log2((l_total + external_p + alpha_e) / (r_total_m + external_p + beta_e))

            new_raw_emission_counts[i,:,0] = l_total
            new_raw_emission_counts[i,:,1] = r_total

            state_flips[i][state_mask] = flip



            #
            # if self.inf_check:
            #     if np.isnan(new_state_sample_log_odds[i]).any():
            #         print("NAN WARNING")
            #         print("================================")
            #         print("================================")
            #         print(list(enumerate(new_raw_emission_counts[i])))
            #         print(list(enumerate(new_state_sample_log_odds[i])))
            #         print("================================")
            #         print("================================")
            #
            #     if np.isinf(new_state_sample_log_odds[i]).any():
            #         print("INFINITY WARNING")
            #         print("================================")
            #         print("================================")
            #         print(list(enumerate(l_total_m)))
            #         print(list(enumerate()))
            #         print(list(enumerate(new_raw_emission_counts[i])))
            #         print(list(enumerate(new_state_sample_log_odds[i])))
            #         print("================================")
            #         print("================================")


        # print(new_state_sample_log_odds)


        assert not (np.isnan(new_state_sample_log_odds).any())


        return new_state_sample_log_odds,new_raw_emission_counts,state_flips

    def compute_background_divergence_odds(self,alpha_e,beta_e,divergence_l,divergence_r):

        left_sum = np.sum(divergence_l,axis=0)
        right_sum = np.sum(divergence_r,axis=0)

        ## If right fit is better than left fit, we would like to flip

        flip = left_sum < right_sum
        no_flip = np.logical_not(flip)

        ## The new log odds are now ready to be computed:

        flipped_left = np.zeros(left_sum.shape)
        flipped_left[no_flip] = left_sum[no_flip]
        flipped_left[flip] = right_sum[flip]
        flipped_right = np.zeros(right_sum.shape)
        flipped_right[no_flip] = right_sum[no_flip]
        flipped_right[flip] = left_sum[flip]

        background_log_odds = np.log2((flipped_left + alpha_e) / (flipped_right + beta_e))

        tiled_odds = np.zeros((1,divergence_l.shape[1],3))
        tiled_odds[0,:,0] = background_log_odds
        tiled_odds[0,:,1] = background_log_odds
        tiled_odds[0,:,2] = background_log_odds

        return tiled_odds


    def recompute_transition_counts(self,live_mask,oracle_indicator_l,oracle_indicator_r,states,node_states,child_state_l,child_state_r):

        print("Recomputing Transition Counts")

        new_transition_counts = np.zeros((states,states))

        transition_mask_l = np.logical_and(live_mask,np.logical_not(oracle_indicator_l))
        transition_mask_r = np.logical_and(live_mask,np.logical_not(oracle_indicator_r))

        # transition_mask = live_mask

        for ps,csl in zip(node_states[transition_mask_l],child_state_l[transition_mask_l]):
            # print(csl)
            # print(ps)
            new_transition_counts[csl,ps] += 1

        for ps,csr in zip(node_states[transition_mask_r],child_state_r[transition_mask_r]):
            # print(csr)
            # print(ps)
            new_transition_counts[csr,ps] += 1

        # print(new_transition_counts)

        return new_transition_counts

    def recompute_oracle_transition_matrix(self,states,oracle_indicator_l,oracle_indicator_r,node_states,child_state_l,child_state_r):

        print("Recomputing oracle transition count")

        new_oracle_transitions = np.zeros((states,states))

        for ps,csl in zip(node_states[oracle_indicator_l],child_state_l[oracle_indicator_l]):
            new_oracle_transitions[csl,ps] += 1

        for ps,csr in zip(node_states[oracle_indicator_r],child_state_r[oracle_indicator_r]):
            new_oracle_transitions[csr,ps] += 1

        new_oracle_transitions[0] = 0

        # print(new_oracle_transitions)

        return new_oracle_transitions


    def recompute_oracle_transition_counts(self,oracle_transition_matrix):

        print("Recomputing oracle transition count")

        new_oracle_transitions = np.ones(oracle_transition_matrix.shape[0])

        new_oracle_transitions += np.sum(oracle_transition_matrix,axis=0)

        new_oracle_transitions[0] = 0

        # print(new_oracle_transitions)

        return new_oracle_transitions

    def compute_state_log_odds_given_divergence(self,divergence_l,divergence_r,flip,node_states,state_sample_log_odds):

        print("Computing state log odds | divergence")

        ## Here we have a wrapper function that allows us to parallelize the node state odds computation
        ## An inner function allows us to compute multiple states at the same time in a process pool

        node_output = self.pool.map(IHMM.node_state_log_odds_given_divergence,zip(divergence_l,divergence_r,flip.T,node_states,repeat(state_sample_log_odds)))

        node_output = np.array(node_output).T

        # if np.isnan(node_output).any():
        #     raise Exception("Computed nan divergence log odds")

        return node_output

    def node_state_log_odds_given_divergence(task):

        ## Here we have a function for computing the log odds of each node's emissions for a state

        dl,dr,flip,home_state,state_sample_log_odds = task

        # print("STATE LOG ODDS DIMENSIONS")
        # print(state_sample_log_odds.shape)
        # print(dl.shape)
        # print(flip.shape)

        ## First we compute the simple case, the odds of a node from a different state transitioning to this state:

        l = np.sum(state_sample_log_odds[:,dl,1],axis=1)
        r = np.sum(state_sample_log_odds[:,dr,1],axis=1)

        f = l-r
        r = r-l

        odds = np.maximum(f,r)

        ## Now the tricky part comes. When evaluating the odds of a node, the odds have to be evaluated as if this node was
        ## NOT in the state it is currently assigned to. This allows unbiased evaluation of small states, and is especially
        ## important for sparse data, where a single emission element can make a substantial difference in odds

        ## First we determine the odds if the node has been flipped:

        if flip[home_state]:

            hsl = np.sum(state_sample_log_odds[home_state,dl,2])
            hsr = np.sum(state_sample_log_odds[home_state,dr,0])

        ## Select the odds of each right sample, assuming one less right sample in the state emissions,
        ## and each left sample assuming one less left sample in the state emissions

            hss = hsl - hsr
            hsf = hsr - hsl

            odds[home_state] = np.maximum(hss,hsf)

        ## Now determine the odds if the node is from this state and flipped

        else:

            hsl = np.sum(state_sample_log_odds[home_state,dr,2])
            hsr = np.sum(state_sample_log_odds[home_state,dl,0])

            hss = hsl - hsr
            hsf = hsr - hsl

            odds[home_state] = np.maximum(hss,hsf)

        # if np.isnan(odds).any():
        #     print(state_sample_log_odds[:,dl,:])
        #     print(state_sample_log_odds[:,dr,:])
        #     print(odds)
        #     raise Exception("Node state odds nan")

        return odds

    def compute_state_odds_given_child_direct_transition(self,beta,transition_counts,node_states,node_child_states):

        ## Here we have to start considering the potential fact that an oracle may be sampled
        ## Since this is the first transition, for simplicity we will simply compute the odds of a direct transition and an oracle transition of any kind

        padded_transition_counts = np.zeros((transition_counts.shape[0],transition_counts.shape[1]+1))
        padded_transition_counts[:,:-1] += transition_counts
        padded_transition_counts[:,-1] += beta

        # print("Transition odds debug")
        # print(padded_transition_counts)

        total_transitions = np.sum(padded_transition_counts,axis=1)

        ## Here we  compute the odds of any other transition besides a given transition. It's important to normalize the transitions by an additional beta.
        ## This is important to prevent potential infinite odds being present when the ONLY transitionto a state is via the oracle.

        counter_odds = np.tile(total_transitions,(padded_transition_counts.shape[1],1)).T + beta
        counter_odds -= padded_transition_counts

        ## Finally we again have to account for the idea that when a node is being evaluated, we have to remove its influence from the transition counts
        ## To do this we will calculate the odds of any given state given a child, and then reduce by one the odds of the state that the node currently occupies

        ## This is important to allow an IHMM to converge from many states to few. When a large number of states are present, the oracle parameter is inferred
        ## to be small, which gives an outsize influence to the transitions that rare states anticipate based on their parent nodes.
        ## Given this, an IHMM can get trapped in a situation where many states containing only one node exist, forcing beta to remain small,
        ## but not allowing the nodes belonging to singleton states to explore other states.

        node_transition_odds = padded_transition_counts[node_child_states]

        # print("direct transition debug")
        # print(node_transition_odds.shape)
        # print(list(node_transition_odds))

        node_transition_odds[np.arange(node_transition_odds.shape[0]),node_states] -= 1

        node_transition_odds[node_transition_odds < 0] = 0
        # print(list(node_transition_odds))

        node_transition_counter_odds = counter_odds[node_child_states]

        # print(node_transition_counter_odds.shape)

        # transition_odds = padded_transition_counts.astype(dtype=float) / counter_odds.astype(dtype=float)

        # print(transition_odds)

        node_state_odds = node_transition_odds.astype(dtype=float) / node_transition_counter_odds.astype(dtype=float)

        node_state_odds[:,0] = 0

        return node_state_odds.T

    def log_sampling(log_weights):
        raw_odds = np.exp2(log_weights)
        sorted_raw = sorted(list(enumerate(raw_odds)),key=lambda x: log_weights[x[0]])[::-1]
        # print(log_weights)
        # print(sorted_raw)
        draw = random.random()*np.sum(raw_odds)
        # print(draw)
        for i,w in sorted_raw:
            # print(draw)
            # print(w)
            draw -= w
            if draw <= 0 or (not np.isfinite(draw)):
                # print(draw)
                # print("DREW")
                # print(i)
                # if i == len(raw_odds)-1:
                #     print("ALERT, NEW STATE")
                #     print(i)
                # if i == len(log_weights)-1:
                #     print("ALWAYS PAIRED")
                #     print(i)
                return i
        # print("WARNING")
        # print(log_weights)
        # print(raw_odds)
        # print(sorted_weights)
        # print("DREW")
        # print(len(raw_odds) - 1)
        return len(raw_odds) - 1


    def sample_states(self,live_mask,state_log_odds):

        print("Sampling states")

        live_nodes = np.sum(live_mask)

        draw_index = self.pool.map(IHMM.log_sampling,state_log_odds[1:,live_mask].T)
        draw_index = [i+1 for i in draw_index]

        new_state_indicator = [di >= state_log_odds.shape[0] - 1 for di in draw_index]

        # if np.isinf(state_log_odds[1:,live_mask]).any():
        #     raise Exception("Inf live log odds")
        #
        # state_raw_odds = np.exp2(state_log_odds)
        #
        # # if np.sum(np.sum(state_raw_odds[:,self.live_mask],axis=0) == 0) > 0:
        # #     print(np.sum(state_raw_odds[:,self.live_mask],axis=0).shape)
        # #     print(np.sum(np.sum(state_raw_odds[:,self.live_mask],axis=0) == 0))
        # #     raise Exception("Some samples with zero total odds")
        # #
        # # if np.sum(np.isnan(state_raw_odds[:,self.live_mask])) > 0:
        # #     raise Exception("NaN live raw odds")
        #
        # #
        # # print("State Raw Odds")
        # # print(state_raw_odds)
        #
        # descending_odds = np.cumsum(state_raw_odds[1:],axis=0)
        #
        # draws = np.random.rand(live_nodes) * descending_odds[-1,live_mask]
        #
        # # if np.sum(draws == 0) > 0:
        # #     raise Exception("Drew a zero")
        #
        # # print("descending_odds")
        # # print(descending_odds)
        # #
        # # print("draws")
        # # print(draws)
        #
        # draw_index = state_log_odds.shape[0] - np.sum(descending_odds[:,live_mask] < np.tile(draws,(descending_odds.shape[0],1)),axis=0)
        #
        # if self.inf_check:
        #     if (draw_index == 0).any():
        #         print(descending_odds[:,live_mask][:,draw_index == 0])
        #         print(draws[draw_index == 0])
        #         raise Exception("Zero Draw Index")
        #     if (draw_index > state_log_odds.shape[0] - 1).any():
        #         mask = draw_index > (descending_odds.shape[0] - 1)
        #         print(state_log_odds[:,live_mask][:,mask])
        #         print(state_raw_odds[:,live_mask][:,mask])
        #         print(descending_odds[:,live_mask][:,mask])
        #         print(draws[mask])
        #         print(draw_index[mask])
        #         print(descending_odds.shape)
        #         print(state_log_odds.shape)
        #         raise Exception("Draw index greater than dimension allows")
        #
        # new_state_indicator = draw_index > (state_log_odds.shape[0] - 1)

        return draw_index, new_state_indicator

    def compute_state_odds_given_oracle(self,gamma,nodes,oracle_transition_counts):

        print("Computing oracle odds")

        print(oracle_transition_counts)

        odds = np.ones(oracle_transition_counts.shape[0]+1)
        odds[:-1] += oracle_transition_counts
        odds[-1] += gamma


        counter_odds = np.sum(odds) * np.ones(odds.shape)
        counter_odds -= odds


        fractional_odds = odds/counter_odds

        ## Here we tile the odds across all nodes, because they are uniform
        fractional_odds = np.tile(fractional_odds,(nodes,1)).T

        # print("Oracle Odds Debug")
        # print(odds)
        # print(counter_odds)
        # print(fractional_odds)

        return fractional_odds

    def sample_oracle_indicator(self,node_state,live_mask,direct_state_odds_l,direct_state_odds_r,oracle_state_odds_l,oracle_state_odds_r):

        # print("Oracle sampler debug")

        states = direct_state_odds_l.shape[0]
        nodes = node_state.shape[0]
        live_nodes = np.sum(live_mask)
        total_samples = live_mask.shape[0]

        # print(direct_state_odds_l.shape)
        # print(direct_state_odds_r.shape)


        # print(self.hidden_states)

        state_mask = np.equal(np.tile(np.arange(states),(live_nodes,1)).T,np.tile(node_state[live_mask],(states,1)))

        # print(np.sum(np.sum(state_mask,axis=0) < 1))
        # print(np.sum(np.sum(state_mask,axis=1) < 1))
        #
        # print(node_state[np.sum(state_mask,axis=0) < 1])

        if self.inf_check:
            if np.sum(state_mask,axis=0).shape[0] != live_nodes:
                print((np.sum(state_mask,axis=0) == 0).shape)
                print(live_mask.shape)
                raise Exception("Switch axies dummy")
            if (np.sum(state_mask,axis=0) == 0).any():
                print((np.sum(state_mask,axis=0) == 0).shape)
                print(node_state[live_mask][(np.sum(state_mask,axis=0) == 0)])
                raise Exception("State mask didn't work")

            if (oracle_state_odds_l[:,live_mask] == 0).any():
                raise Exception("Zero oracle state odds")
            if (oracle_state_odds_r[:,live_mask] == 0).any():
                raise Exception("Zero oracle state odds")

        #
        # print("problem_node_state")
        # print(np.tile(np.arange(direct_state_odds_l.shape[0]),(direct_state_odds_l.shape[1],1))[np.sum(state_mask,axis=0) == 0])
        # print(node_state[np.sum(state_mask,axis=0) == 0])

        direct_state_odds_l = direct_state_odds_l[:,live_mask][state_mask]
        direct_state_odds_r = direct_state_odds_r[:,live_mask][state_mask]

        # print(direct_state_odds_l.shape)
        # print(direct_state_odds_r.shape)
        # print(state_mask.shape)
        # print(state_mask.shape)
        # print(oracle_state_odds_l.shape)
        # print(oracle_state_odds_r.shape)

        oracle_state_odds_l = oracle_state_odds_l[:,live_mask][state_mask]
        oracle_state_odds_r = oracle_state_odds_r[:,live_mask][state_mask]

        oracle_probability_l = np.zeros(nodes)
        oracle_probability_r = np.zeros(nodes)

        oracle_probability_l[live_mask] = (oracle_state_odds_l / (oracle_state_odds_l + direct_state_odds_l))
        oracle_probability_r[live_mask] = (oracle_state_odds_r / (oracle_state_odds_r + direct_state_odds_r))

        if self.inf_check:
            if np.isnan(oracle_probability_l).any():
                raise Exception("Nan Oracle probability")
            if np.isnan(oracle_probability_r).any():
                raise Exception("Nan Oracle probability")
            if np.isinf(oracle_probability_l).any():
                raise Exception("Inf Oracle probability")
            if np.isinf(oracle_probability_r).any():
                raise Exception("Inf Oracle probability")

        # print("Oracle Indicator Debug")
        # print(list(oracle_probability_l))
        # print(list(oracle_probability_r))

        # if np.sum(np.isnan(oracle_probability_l[self.live_mask] + np.isnan(oracle_probability_r[self.live_mask]))) > 0:
        #     raise Exception("NaN Oracle Probability")

        oracle_indicator_l = np.random.rand(oracle_probability_l.shape[0]) < oracle_probability_l
        oracle_indicator_r = np.random.rand(oracle_probability_r.shape[0]) < oracle_probability_r

        return oracle_indicator_l,oracle_indicator_r


    def generate_new_states(self,states,new_state_mask):

        print("Labeling new states")
        print(f"Label:{states+1}")
        # total_new_states = np.sum(new_state_mask)
        # return np.arange(states,states+total_new_states)

        return states + 1

    def lr_finite(self,state):
        return expit(np.log2(self.state_raw_emission_counts[state][:,0]/self.state_raw_emission_counts[state][:,1]))

    def state_node_odds(self,state):

        state_mask = self.state_masks[state]

        return self.state_log_odds[state,state_mask]

    def pad_root_transitions(self,raw_counts):
        for node in self.nodes:
            if node.parent is None:
                raw_counts[self.node_states[node.index],0] += 1
        return raw_counts

    def most_likely_parent_to_child(self):

        raw_counts = self.raw_transition_counts()

        raw_counts = self.pad_root_transitions(raw_counts)

        most_likely_transition_matrix = np.zeros((self.hidden_states,self.hidden_states))

        for hidden_state,transitions in enumerate(raw_counts[1:]):
            print(hidden_state)
            print(transitions)
            most_likely_parent = np.argmax(transitions)
            print(most_likely_parent)
            most_likely_transition_matrix[hidden_state+1,most_likely_parent] += 1

        return most_likely_transition_matrix.T

    def raw_transition_counts(self):

        print("Recomputing Transition Counts")

        self.establish_parameters()

        states = self.hidden_states

        transition_mask = self.live_mask

        new_transition_counts = np.zeros((states+1,states+1))

        # transition_mask = live_mask

        for ps,csl in zip(self.node_states[transition_mask],self.child_state_l[transition_mask]):
            # print(csl)
            # print(ps)
            new_transition_counts[csl,ps] += 1

        for ps,csr in zip(self.node_states[transition_mask],self.child_state_r[transition_mask]):
            # print(csr)
            # print(ps)
            new_transition_counts[csr,ps] += 1

        # print(new_transition_counts)

        return new_transition_counts

    def backup(self,location):
        self.pool = None
        with open(location,mode='bw') as f:
            pickle.dump(self,f)

    def reconstitute(location):
        with open(location,mode='br') as f:
            braider = pickle.load(f)
            braider.pool = mp.Pool()
            return braider

    def hidden_state_to_nodes(self,hidden_state):
        node_indices = np.arange(self.total_nodes)[self.state_masks[hidden_state]]
        return [self.nodes[ni] for ni in node_indices]

    def state_lr_samples(self,hidden_state):
        finite = self.lr_finite(hidden_state)
        left = np.arange(self.total_samples)[finite < .5]
        right = np.arange(self.total_samples)[finite >= .5]
        return left,right

    def state_lr_gradient(self,hidden_state):
        return self.state_sample_log_odds[hidden_state]

    #
    #
    #
    # def raw_transition_matrix(self):
    #
    #     states = self.hidden_states
    #
    #     new_transition_counts = np.zeros((states,states))
    #
    #     # transition_mask = np.logical_and(live_mask,np.logical_not(oracle_indicator))
    #
    #     transition_mask = self.live_mask
    #
    #     for ps,csl in zip(self.node_states[transition_mask],self.child_state_l[transition_mask]):
    #         # print(csl)
    #         # print(ps)
    #         new_transition_counts[csl,ps] += 1
    #
    #     for ps,csr in zip(self.node_states[transition_mask],self.child_state_r[transition_mask]):
    #         # print(csr)
    #         # print(ps)
    #         new_transition_counts[csr,ps] += 1
    #
    #     print(new_transition_counts)
    #
    #     return new_transition_counts



    #
    # def resample_node_states(self,transition_odds,sample_odds,node_states,node_divergences,children_l,children_r):
    #
    #     state_log_odds = np.zeros((self.hidden_states,self.total_nodes))
    #
    #     state_log_odds += self.state_log_odds_given_child()







##
