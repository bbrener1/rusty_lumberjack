### Infinite Hidden Markov Model for clustering together tree nodes generated by Random Forests

import numpy as np
import random
# import pymc3 as pm
from functools import reduce
from scipy.misc import comb as nCk
from tree_reader import Node as TreeReaderNode

from scipy.special import logit,expit
from scipy.special import gamma as gamma_f

import multiprocessing as mp

import matplotlib.pyplot as plt

## This model contains several interdependent variables:

##  - Hidden state sequence for nodes
##  - Transition probablities between hidden states
##  - Probability of any given sample emitting 0 or 1 when in a given state
##  - Hyperparameters governing the generative mechanism of the states

## These variables are sampled sequentially

class IHMM():
    def __init__(self,forest,alpha=1,beta=1,gamma=1,alpha_e=.5,beta_e=.5,start_states=20):

        # self.pool = mp.Pool()

        self.forest = forest

        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma

        self.alpha_e = alpha_e
        self.beta_e = beta_e

        self.hidden_states = start_states

        self.nodes = forest.nodes()
        self.live_nodes = forest.roots() + forest.stems()
        self.live_mask = np.zeros(len(self.nodes),dtype=bool)

        for node in self.live_nodes:
            self.live_mask[node.index] = True

        self.total_samples = len(forest.samples)
        self.total_nodes = len(self.nodes)

        self.node_states = np.zeros(self.total_nodes,dtype=int)

        self.child_index_l = np.zeros(self.total_nodes,dtype=int)
        self.child_index_r = np.zeros(self.total_nodes,dtype=int)
        self.child_state_l = np.zeros(self.total_nodes,dtype=int)
        self.child_state_r = np.zeros(self.total_nodes,dtype=int)

        for node in self.live_nodes:
            self.child_index_l[node.index] = node.children[0].index
            self.child_index_r[node.index] = node.children[1].index

        self.node_samples = forest.node_sample_encoding(self.nodes)

        self.divergence_l = np.zeros((self.total_nodes,self.total_samples),dtype=bool)
        self.divergence_r = np.zeros((self.total_nodes,self.total_samples),dtype=bool)

        for node in self.live_nodes:
            l,r = node.lr_encoding_vectors()
            self.divergence_l[node.index] = l
            self.divergence_r[node.index] = r

        for node in self.live_nodes:
            self.node_states[node.index] = random.randint(1,self.hidden_states-1)

        self.oracle_indicator = np.random.rand(self.total_nodes) < 1/self.hidden_states
        self.oracle_indicator[np.logical_not(self.live_mask)] = False

        self.state_masks = np.zeros((self.hidden_states,self.total_nodes),dtype=bool)

        self.state_sample_log_odds = np.zeros((self.hidden_states,self.total_samples))


    ## Here we begin the methods for updating the state of the model over many "sweeps"

    ## Things that stay constant:
    ## Divergence masks
    ##    - These are the emissions of 0 or 1 per sample for a given node
    ## Number of samples
    ## Number of nodes
    ## State of nodes that aren't live or marked as null state
    ##    - These nodes don't have a divergence (probably because they're leaves), so they can't be modeled
    ## Node sample encoding
    ## Node relations (eg child indices)
    ##    -  Topology of the forest remains constant, we're only trying to learn it

    ## Things that update:
    ## Node states for live nodes
    ## Number of states
    ## Log odds of a sample emitting "1" vs "0" in a state
    ## Number of transitions between states
    ## State of children
    ## Hyperparameters

    ## Dependence flow:

    ## Node state gives gives=>
    ##  - Number of hidden states
    ##  - State masks

    ## - Number of states + masks + oracle transition indicator =>
    ##  - Transitions
    ##  - Oracle transitions
    ##  - State sample log odds

    ## - Transitions + number of states =>
    ##  - Transition log odds

    ## - Oracle indicator + Transitions =>
    ##  - MAP Hyperparameters

    ###### HERE WE BEGIN TO RECOMPUTE THE NODE STATE ####

    ## - Transition log odds + state sample log odds =>
    ##  - Log odds of direct state transitions per node
    ##  - Log odds of oracle per node

    ####### HERE WE DO THE FIRST SAMPLING STEP ##########

    ## - Oracle indicator + oracle log odds =>
    ##  - Log odds given oracle
    ##  - Log odds of secondary oracle

    ################ SECOND SAMPLING STEP ###############

    ##  - New states discovered
    ##  - Loop back to recomputing transitions & hypers


    def sweep(self):

        print("Sweep debug")

        print(self.hidden_states)
        print(self.node_states)
        print(np.sum(self.state_masks,axis=1))

        self.node_states = self.clean_state_indeces(self.node_states)
        self.update_node_relations()
        self.state_masks = self.recompute_state_masks(self.node_states)
        self.state_sample_log_odds = self.recompute_state_sample_log_odds(self.hidden_states,self.total_samples,self.alpha_e,self.beta_e,self.state_masks,self.state_sample_log_odds,self.divergence_l,self.divergence_r)
        self.transition_counts = self.recompute_transition_counts(self.live_mask,self.oracle_indicator,self.hidden_states,self.node_states,self.child_state_l,self.child_state_r)
        self.oracle_transition_counts = self.recompute_oracle_transition_counts(self.hidden_states,self.oracle_indicator,self.node_states)

        self.sample_hypers()

        new_node_states = np.zeros(self.node_states.shape,dtype=int)
        new_oracle_indicator = np.zeros(self.node_states.shape,dtype=bool)

        state_log_odds_given_divergence = self.state_log_odds_given_divergence(self.divergence_l,self.divergence_r,self.state_sample_log_odds)

        state_log_odds_given_child_l = self.state_log_odds_given_child_first_transition(self.beta,self.transition_counts,self.child_state_l)
        state_log_odds_given_child_r = self.state_log_odds_given_child_first_transition(self.beta,self.transition_counts,self.child_state_r)

        state_log_odds = self.state_log_odds_first_sample_layer(state_log_odds_given_divergence,state_log_odds_given_child_l,state_log_odds_given_child_r)

        first_layer_draws,first_oracle_indicator = self.sample_first_layer(self.live_mask,state_log_odds)

        new_node_states[self.live_mask] = first_layer_draws
        new_oracle_indicator[self.live_mask] = first_oracle_indicator

        oracle_log_odds = self.state_log_odds_given_oracle(self.gamma,self.oracle_transition_counts)

        state_log_odds_given_oracle = self.state_log_odds_second_sample_layer(new_oracle_indicator,oracle_log_odds,state_log_odds_given_divergence)

        second_layer_draws,new_state_indicator = self.sample_second_layer(new_oracle_indicator,state_log_odds_given_oracle)

        new_node_states[new_oracle_indicator] = second_layer_draws
        new_state_spaced_indicator = np.zeros(self.total_nodes,dtype=bool)
        new_state_spaced_indicator[new_oracle_indicator] = new_state_indicator

        new_node_states[new_state_spaced_indicator] = self.generate_new_states(self.hidden_states,new_state_indicator)

        self.node_states = new_node_states
        self.oracle_indicator = new_oracle_indicator



    def sample_hypers(self):

        print(f"Beta:{self.beta}")
        print(f"Gamma:{self.gamma}")

        self.recompute_beta()
        self.recompute_gamma()

        print(f"Beta:{self.beta}")
        print(f"Gamma:{self.gamma}")


    def recompute_beta(self):

        k = self.hidden_states

        sums = np.sum(self.transition_counts,axis=1)

        max_sum = int(np.max(sums))

        log_sequence = np.log2(np.arange(1,max_sum*2))

        likelihood_sequence = np.zeros(max_sum)

        for i in range(self.hidden_states):
            transitions = self.transition_counts[i]
            total = int(sums[i])
            non_zero = int(np.sum(transitions > 0))
            l2ls = lambda b: (non_zero * log_sequence[b] - np.sum(log_sequence[b:total+b]))
            likelihood_sequence += np.array([l2ls(b) for b in range(max_sum)])

        self.beta = np.argmax(likelihood_sequence)+1

    def recompute_gamma(self):

        oracle_total = int(np.sum(self.oracle_indicator) + self.gamma)

        log_sequence = np.log2(np.arange(1,oracle_total*2))

        k = self.hidden_states

        l2l = lambda g: (k * np.log2(g) - np.sum(log_sequence[g:oracle_total+g]))

        likelihood_sequence = np.array([l2l(g) for g in range(oracle_total)])

        self.gamma = np.argmax(likelihood_sequence)+1


    def update_node_relations(self):

        self.child_state_l[self.live_mask] = self.node_states[self.child_index_l][self.live_mask]
        self.child_state_r[self.live_mask] = self.node_states[self.child_index_r][self.live_mask]

    def clean_state_indeces(self,node_states):

        print("State Index Cleanup")
        new_states = sorted(list(set(node_states)))
        print(new_states)
        new_indices = {old_index:i for i,old_index in enumerate(new_states)}
        print(new_indices)

        new_state_sequence = np.zeros(node_states.shape,dtype=int)

        for i,old_state in enumerate(node_states):
            new_state_sequence[i] = new_indices[old_state]

        self.hidden_states = len(new_states)

        print(self.hidden_states)

        new_state_sample_log_odds = np.zeros((self.hidden_states,self.total_samples))

        for old_index,state in enumerate(self.state_sample_log_odds):
            if old_index in new_indices:
                new_state_sample_log_odds[new_indices[old_index]] = state

        self.state_sample_log_odds = new_state_sample_log_odds

        print(new_state_sequence)

        return new_state_sequence

    def recompute_state_masks(self,node_states):

        print("State Mask Debug")

        new_states = self.hidden_states

        new_state_masks = np.zeros((new_states,node_states.shape[0]),dtype=bool)

        for state in range(new_states):
            new_state_masks[state] = node_states == state

        print(new_state_masks.shape)

        return new_state_masks


    def recompute_state_sample_log_odds(self,states,samples,alpha_e,beta_e,state_masks,state_sample_log_odds,divergence_l,divergence_r):

        print("Recompute Sample Log Odds Debug")

        new_state_sample_log_odds = np.zeros((states,samples))

        print(new_state_sample_log_odds.shape)

        for i,state_mask in list(enumerate(state_masks))[1:]:

            ## First we want:
            ##  -only nodes in state
            ##  -left and right mask each
            ##      -This matrix is node x sample, true if left/right

            l = divergence_l[state_mask]
            r = divergence_r[state_mask]

            print(i)
            print(l.shape)
            print(r.shape)

            ## We want to figure out whether to use the right or the left split of the node:

            ## First take each sample mask and use it to select log odds from state sample log odds

            state_sample_log_tile = np.tile(state_sample_log_odds[i],(np.sum(state_mask),1))

            print(state_sample_log_tile.shape)

            left_log_odds = np.zeros(l.shape)
            left_log_odds[l]
            state_sample_log_tile[l]
            left_log_odds[l] = state_sample_log_tile[l]

            right_log_odds = np.zeros(r.shape)
            right_log_odds[r] = state_sample_log_tile[r]

            ## Next we sum the log odds to obtain total log odds of the fit of each side of the divergence
            ## to the state model

            left_fit = np.sum(left_log_odds,axis=1)
            right_fit = np.sum(right_log_odds,axis=1)

            ## If right fit is better than left fit, we would like to flip

            flip = right_fit > left_fit

            ## Next we want to figure out the totals going left and right

            l_total = np.sum(l[np.logical_not(flip)],axis=0) + np.sum(r[flip],axis=0)
            r_total = np.sum(r[np.logical_not(flip)],axis=0) + np.sum(r[flip],axis=0)



            l_total = alpha_e + l_total
            r_total = alpha_e + beta_e + r_total

            ## The new log odds are now ready to be computed:

            new_state_sample_log_odds[i] = np.log2(l_total/r_total)

        print(new_state_sample_log_odds)

        return new_state_sample_log_odds

    def recompute_transition_counts(self,live_mask,oracle_indicator,states,node_states,child_state_l,child_state_r):

        print("Transition Count Debug")

        new_transition_counts = np.zeros((states,states))

        # transition_mask = np.logical_and(live_mask,np.logical_not(oracle_indicator))

        transition_mask = live_mask

        for ps,csl in zip(node_states[transition_mask],child_state_l[transition_mask]):
            # print(csl)
            # print(ps)
            new_transition_counts[csl,ps] += 1

        for ps,csr in zip(node_states[transition_mask],child_state_r[transition_mask]):
            # print(csr)
            # print(ps)
            new_transition_counts[csr,ps] += 1

        print(new_transition_counts)

        return new_transition_counts

    def recompute_oracle_transition_counts(self,states,oracle_indicator,node_states):

        print("Oracle transition count debug")

        new_oracle_transitions = np.ones(states)

        for ns in node_states[oracle_indicator]:
            new_oracle_transitions[ns] += 1

        new_oracle_transitions[0] = 0

        print(new_oracle_transitions)

        return new_oracle_transitions

    def state_log_odds_given_divergence(self,divergence_l,divergence_r,state_sample_log_odds):

        print("Divergence log odds debug")

        state_log_odds = np.zeros((self.hidden_states,self.total_nodes))

        l = np.zeros((self.total_nodes,self.total_samples))
        r = np.zeros((self.total_nodes,self.total_samples))

        for i,state in enumerate(state_sample_log_odds):

            tile_odds = np.tile(state,(self.total_nodes,1))

            print(tile_odds.shape)

            l[:,:] = 0
            r[:,:] = 0

            l[divergence_l] = tile_odds[divergence_l]
            r[divergence_r] = tile_odds[divergence_r]

            l_state_odds = np.sum(l,axis=1)
            r_state_odds = np.sum(r,axis=1)

            l_combined = l_state_odds - r_state_odds
            r_combined = r_state_odds - l_state_odds

            state_log_odds[i] = np.maximum(l_combined,r_combined)

        print(state_log_odds)

        return state_log_odds

    def state_log_odds_given_child_first_transition(self,beta,transition_counts,node_child_states):

        ## Here we have to start considering the potential fact that an oracle may be sampled
        ## Since this is the first transition, for simplicity we will simply compute the odds of a direct transition and an oracle transition of any kind

        padded_transition_counts = np.zeros((transition_counts.shape[0],transition_counts.shape[1]+1))
        padded_transition_counts[:,:-1] += transition_counts
        padded_transition_counts[:,-1] += beta

        print("Transition odds debug")
        print(padded_transition_counts)

        total_transitions = np.sum(padded_transition_counts,axis=1)

        counter_odds = np.tile(total_transitions,(padded_transition_counts.shape[1],1)).T
        counter_odds -= padded_transition_counts

        transition_odds = padded_transition_counts.astype(dtype=float) / counter_odds.astype(dtype=float)

        print(transition_odds)

        transition_log_odds = np.log2(transition_odds)

        print(transition_log_odds)

        node_state_log_odds = transition_log_odds[node_child_states].T

        return node_state_log_odds

    def state_log_odds_first_sample_layer(self,state_log_odds_given_divergence,state_log_odds_given_child_l,state_log_odds_given_child_r):

        print("Node state log odds debug")

        state_log_odds = np.zeros((self.hidden_states+1,self.total_nodes))

        state_log_odds[:-1,:] += state_log_odds_given_divergence

        state_log_odds += state_log_odds_given_child_l
        state_log_odds += state_log_odds_given_child_r

        print(state_log_odds[:,self.live_mask])

        return state_log_odds

    def sample_first_layer(self,live_mask,state_log_odds):

        print("Draw debug")

        live_nodes = np.sum(live_mask)

        state_raw_odds = np.exp2(state_log_odds)

        print("State Raw Odds")
        print(state_raw_odds)

        descending_odds = np.cumsum(state_raw_odds,axis=0)

        draws = np.random.rand(live_nodes) * descending_odds[-1,live_mask]

        print("descending_odds")
        print(descending_odds)

        print("draws")
        print(draws)

        draw_index = np.sum(descending_odds[:,live_mask] < np.tile(draws,(descending_odds.shape[0],1)),axis=0) + 1

        oracle_indicator = draw_index >= descending_odds.shape[0]-1

        return draw_index, oracle_indicator

    def state_log_odds_given_oracle(self,gamma,oracle_transition_counts):

        print("Oracle Odds Debug")

        print(oracle_transition_counts)

        odds = np.zeros(oracle_transition_counts.shape[0]+1)
        odds[:-1] = oracle_transition_counts
        odds[-1] = gamma


        counter_odds = np.sum(odds) * np.ones(odds.shape)
        counter_odds -= odds

        log_odds = np.log2(odds/counter_odds)

        print(log_odds)

        return log_odds

    def state_log_odds_second_sample_layer(self,oracle_mask,oracle_odds,state_log_odds_given_divergence):

        print("Second layer debug")


        state_log_odds = np.zeros((state_log_odds_given_divergence.shape[0]+1,state_log_odds_given_divergence.shape[1]))
        state_log_odds[:-1,:] = state_log_odds_given_divergence

        print(state_log_odds)
        print(oracle_odds)

        state_log_odds[:,oracle_mask] += np.tile(oracle_odds,(np.sum(oracle_mask),1)).T

        return state_log_odds

    def sample_second_layer(self,oracle_mask,state_log_odds):

        oracle_nodes = np.sum(oracle_mask)

        state_raw_odds = np.exp2(state_log_odds)

        print("State Raw Odds")
        print(state_raw_odds)

        descending_odds = np.cumsum(state_raw_odds,axis=0)

        draws = np.random.rand(oracle_nodes) * descending_odds[-1,oracle_mask]

        print("descending_odds")
        print(descending_odds)

        print("draws")
        print(draws)

        draw_index = np.sum(descending_odds[:,oracle_mask] < np.tile(draws,(descending_odds.shape[0],1)),axis=0) + 1

        new_state_indicator = draw_index >= descending_odds.shape[0]-1

        return draw_index, new_state_indicator

    def generate_new_states(self,states,new_state_mask):

        total_new_states = np.sum(new_state_mask)

        return states
        # return np.arange(states,states+total_new_states)

    def lr_finite(self,state):
        return expit(self.state_sample_log_odds[state])

    def raw_transition_matrix(self):

        states = self.hidden_states

        new_transition_counts = np.zeros((states,states))

        # transition_mask = np.logical_and(live_mask,np.logical_not(oracle_indicator))

        transition_mask = self.live_mask

        for ps,csl in zip(self.node_states[transition_mask],self.child_state_l[transition_mask]):
            # print(csl)
            # print(ps)
            new_transition_counts[csl,ps] += 1

        for ps,csr in zip(self.node_states[transition_mask],self.child_state_r[transition_mask]):
            # print(csr)
            # print(ps)
            new_transition_counts[csr,ps] += 1

        print(new_transition_counts)

        return new_transition_counts



    #
    # def resample_node_states(self,transition_odds,sample_odds,node_states,node_divergences,children_l,children_r):
    #
    #     state_log_odds = np.zeros((self.hidden_states,self.total_nodes))
    #
    #     state_log_odds += self.state_log_odds_given_child()







##
