### Infinite Hidden Markov Model for clustering together tree nodes generated by Random Forests

import numpy as np
import random
# import pymc3 as pm
from functools import reduce
from scipy.misc import comb as nCk
from tree_reader import Node as TreeReaderNode

from itertools import repeat

from scipy.special import logit,expit
from scipy.special import gamma as gamma_f

import multiprocessing as mp

import matplotlib.pyplot as plt

## This model contains several interdependent variables:

##  - Hidden state sequence for nodes
##  - Transition probablities between hidden states
##  - Probability of any given sample emitting 0 or 1 when in a given state
##  - Hyperparameters governing the generative mechanism of the states

## These variables are sampled sequentially

class IHMM():
    def __init__(self,forest,alpha=1,beta=1,gamma=1,alpha_e=.5,beta_e=.5,start_states=20):

        self.pool = mp.Pool()

        self.forest = forest

        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma

        self.alpha_e = alpha_e
        self.beta_e = beta_e

        self.hidden_states = start_states

        self.nodes = forest.nodes()
        self.live_nodes = forest.roots() + forest.stems()
        self.live_mask = np.zeros(len(self.nodes),dtype=bool)

        for node in self.live_nodes:
            self.live_mask[node.index] = True

        self.total_samples = len(forest.samples)
        self.total_nodes = len(self.nodes)

        self.node_states = np.zeros(self.total_nodes,dtype=int)

        self.child_index_l = np.zeros(self.total_nodes,dtype=int)
        self.child_index_r = np.zeros(self.total_nodes,dtype=int)
        self.child_state_l = np.zeros(self.total_nodes,dtype=int)
        self.child_state_r = np.zeros(self.total_nodes,dtype=int)

        for node in self.live_nodes:
            self.child_index_l[node.index] = node.children[0].index
            self.child_index_r[node.index] = node.children[1].index

        self.node_samples = forest.node_sample_encoding(self.nodes)

        self.divergence_l = np.zeros((self.total_nodes,self.total_samples),dtype=bool)
        self.divergence_r = np.zeros((self.total_nodes,self.total_samples),dtype=bool)

        for node in self.live_nodes:
            l,r = node.lr_encoding_vectors()
            self.divergence_l[node.index] = l
            self.divergence_r[node.index] = r

        for node in self.live_nodes:
            self.node_states[node.index] = random.randint(1,self.hidden_states-1)

        self.oracle_indicator_l = np.random.rand(self.total_nodes) < 1/self.hidden_states
        self.oracle_indicator_l[np.logical_not(self.live_mask)] = False

        self.oracle_indicator_r = np.random.rand(self.total_nodes) < 1/self.hidden_states
        self.oracle_indicator_r[np.logical_not(self.live_mask)] = False

        self.state_masks = np.zeros((self.hidden_states,self.total_nodes),dtype=bool)

        self.state_sample_log_odds = np.zeros((self.hidden_states,self.total_samples))


    ## Here we begin the methods for updating the state of the model over many "sweeps"

    ## Things that stay constant:
    ## Divergence masks
    ##    - These are the emissions of 0 or 1 per sample for a given node
    ## Number of samples
    ## Number of nodes
    ## State of nodes that aren't live or marked as null state
    ##    - These nodes don't have a divergence (probably because they're leaves), so they can't be modeled
    ## Node sample encoding
    ## Node relations (eg child indices)
    ##    -  Topology of the forest remains constant, we're only trying to learn it

    ## Things that update:
    ## Node states for live nodes
    ## Number of states
    ## Log odds of a sample emitting "1" vs "0" in a state
    ## Number of transitions between states
    ## State of children
    ## Hyperparameters

    ## Dependence flow:

    ## Node state gives gives=>
    ##  - Number of hidden states
    ##  - State masks

    ## - Number of states + masks + oracle transition indicator =>
    ##  - Transitions
    ##  - Oracle transitions
    ##  - State sample log odds

    ## - Transitions + number of states =>
    ##  - Transition log odds

    ## - Oracle indicator + Transitions =>
    ##  - MAP Hyperparameters

    ###### HERE WE BEGIN TO RECOMPUTE THE NODE STATE ####

    ## - Transition log odds + state sample log odds =>
    ##  - Log odds of direct state transitions per node
    ##  - Log odds of oracle per node

    ####### HERE WE DO THE FIRST SAMPLING STEP ##########

    ## - Oracle indicator + oracle log odds =>
    ##  - Log odds given oracle
    ##  - Log odds of secondary oracle

    ################ SECOND SAMPLING STEP ###############

    ##  - New states discovered
    ##  - Loop back to recomputing transitions & hypers


    def sweep(self):

        self.establish_parameters()

        ### The above methods establish a description of the current state.

        ### The methods below establish the log odds of each given state for each given node, and whether an oracle was used to reach it

        new_node_states = np.zeros(self.total_nodes,dtype=int)
        new_state_indicator = np.zeros(self.total_nodes,dtype=bool)
        new_oracle_indicator = np.zeros(self.total_nodes,dtype=bool)

        ## First we establish the log odds of a given state based on the divergence observed

        self.state_log_odds_given_divergence = self.compute_state_log_odds_given_divergence(self.divergence_l,self.divergence_r,self.state_sample_log_odds)

        ## We need to pad this with the odds of a new state. A priori we have no information about this new state based on divergence, so the odds are 0

        self.state_log_odds_given_divergence = np.concatenate((self.state_log_odds_given_divergence,np.zeros((1,self.state_log_odds_given_divergence.shape[1]))),axis=0)


        #### IMPORTANT ####

        ## This next section works with raw odds because there is a need to add together the odds of a state given oracle and given no oracle_mask

        #### DO NOT MIX ODDS AND LOG ODDS, BAD ####

        ## Next we establish the odds of a given state or the oracle given its children

        self.direct_state_odds_given_child_l = self.compute_state_log_odds_given_child_direct_transition(self.beta,self.transition_counts,self.child_state_l)
        self.direct_state_odds_given_child_r = self.compute_state_log_odds_given_child_direct_transition(self.beta,self.transition_counts,self.child_state_r)

        ## We extract the odds of visiting the oracle for each given node and tile them

        self.oracle_odds_given_child_l = np.tile(self.direct_state_odds_given_child_l[-1],(self.hidden_states + 1,1))
        self.oracle_odds_given_child_r = np.tile(self.direct_state_odds_given_child_r[-1],(self.hidden_states + 1,1))

        # print("ORACLE_ODDS_DEBUG")
        # print(self.oracle_odds_given_child_l.shape)
        # print(self.oracle_odds_given_child_r.shape)

        ### THIS IS IMPORTANT ###
        ## We NOW set the bottom rows to zero, so that it will be filled in with the odds of a novel state momentarily
        self.direct_state_odds_given_child_l[-1] = 0
        self.direct_state_odds_given_child_r[-1] = 0

        ## Next we need to establish the odds of a given state given that an oracle was visited
        ## These are tiled across every node because they are uniform

        self.oracle_odds = self.compute_state_odds_given_oracle(self.gamma,self.total_nodes,self.oracle_transition_counts)

        ## Next we get the odds of obtaining each state by the oracle route through multiplication:

        self.state_odds_given_oracle_l = self.oracle_odds_given_child_l * self.oracle_odds
        self.state_odds_given_oracle_r = self.oracle_odds_given_child_r * self.oracle_odds


        # print("ORACLE_ODDS_DEBUG2")
        # print(self.state_odds_given_oracle_l.shape)
        # print(self.state_odds_given_oracle_r.shape)

        ## Finally we combine the odds and transform them into log form
        ## NOTE the final row is now the odds of a novel state, because it is the odds of visiting the oracle multiplied by the odds of obtaining a new state from the oracle

        self.state_odds_given_child_l = self.direct_state_odds_given_child_l + self.state_odds_given_oracle_l
        self.state_odds_given_child_r = self.direct_state_odds_given_child_r + self.state_odds_given_oracle_r

        ## And here we transform the plain odds into log odds:

        self.state_log_odds_given_child_l = np.log2(self.state_odds_given_child_l)
        self.state_log_odds_given_child_r = np.log2(self.state_odds_given_child_r)



        ## Finally we want to combine all log odds and sample the resulting distribution

        self.state_log_odds = self.state_log_odds_given_divergence + self.state_log_odds_given_child_l + self.state_log_odds_given_child_r

        new_node_states[self.live_mask],new_state_indicator[self.live_mask] = self.sample_states(self.live_mask,self.state_log_odds)

        # print("ORACLE_INDICATOR_DEBUG")
        # print(new_node_states.shape)
        # print(self.direct_state_odds_given_child_l.shape)
        # print(self.direct_state_odds_given_child_r.shape)
        # print(self.state_odds_given_oracle_l.shape)
        # print(self.state_odds_given_oracle_r.shape)

        new_oracle_indicator_l,new_oracle_indicator_r = self.sample_oracle_indicator(new_node_states,self.direct_state_odds_given_child_l,self.direct_state_odds_given_child_r,self.state_odds_given_oracle_l,self.state_odds_given_oracle_r)

        # print(new_oracle_indicator_l.shape)
        # print(new_oracle_indicator_r.shape)


        self.node_states = new_node_states
        self.oracle_indicator_l = new_oracle_indicator_l
        self.oracle_indicator_r = new_oracle_indicator_r

    def max_likelihood_sweep(self):

        self.sweep()
        new_node_states = np.zeros(self.node_states.shape[0])
        new_node_states[self.live_mask] = np.argmax(self.state_log_odds[:,self.live_mask],axis=0)
        self.node_states = new_node_states
        self.establish_parameters()

    def establish_parameters(self):
        print("Sweep debug")

        print(self.hidden_states)
        print(self.node_states)
        print(list(np.sum(self.state_masks,axis=1)))

        self.node_states = self.clean_state_indeces(self.node_states)
        self.update_node_relations()
        self.state_masks = self.recompute_state_masks(self.node_states)
        self.state_sample_log_odds,self.state_raw_sample_odds = self.recompute_state_sample_log_odds(self.hidden_states,self.total_samples,self.alpha_e,self.beta_e,self.state_masks,self.state_sample_log_odds,self.divergence_l,self.divergence_r)
        self.transition_counts = self.recompute_transition_counts(self.live_mask,self.oracle_indicator_l,self.oracle_indicator_r,self.hidden_states,self.node_states,self.child_state_l,self.child_state_r)
        self.oracle_transition_matrix = self.recompute_oracle_transition_matrix(self.hidden_states,self.oracle_indicator_l,self.oracle_indicator_r,self.node_states,self.child_state_l,self.child_state_r)
        self.oracle_transition_counts = self.recompute_oracle_transition_counts(self.oracle_transition_matrix)

        self.sample_hypers()

    def sample_hypers(self):


        print("Sampling Hypers")
        # print(f"Beta:{self.beta}")
        # print(f"Gamma:{self.gamma}")

        self.recompute_beta()
        self.recompute_gamma()

        print(f"Beta:{self.beta}")
        print(f"Gamma:{self.gamma}")


    def recompute_beta(self):

        k = self.hidden_states

        sums = np.sum(self.transition_counts,axis=1)

        max_sum = int(np.max(sums))

        log_sequence = np.log2(np.arange(1,max_sum*2))

        likelihood_sequence = np.zeros(max_sum)[1:]

        for i in range(self.hidden_states):
            transitions = self.transition_counts[i]
            total = int(sums[i])
            non_zero = int(np.sum(transitions > 0))
            l2ls = lambda b: (non_zero * log_sequence[b] - np.sum(log_sequence[b:total+b]))
            likelihood_sequence += np.array([l2ls(b) for b in range(1,max_sum)])

        self.beta = np.argmax(likelihood_sequence)

    def recompute_gamma(self):

        oracle_total = int(np.sum(self.oracle_transition_counts))

        log_sequence = np.log2(np.arange(1,(oracle_total+1)*2))

        k = self.hidden_states

        l2l = lambda g: (k * np.log2(g) - np.sum(log_sequence[g:oracle_total+g]))

        likelihood_sequence = np.array([l2l(g) for g in range(oracle_total+1)])

        self.gamma = np.argmax(likelihood_sequence)+1


    def update_node_relations(self):

        self.child_state_l[self.live_mask] = self.node_states[self.child_index_l][self.live_mask]
        self.child_state_r[self.live_mask] = self.node_states[self.child_index_r][self.live_mask]

    def clean_state_indeces(self,node_states):

        print("State Index Cleanup")
        new_states = sorted(list(set(node_states)))
        # print(new_states)
        new_indices = {old_index:i for i,old_index in enumerate(new_states)}
        # print(new_indices)

        new_state_sequence = np.zeros(node_states.shape,dtype=int)

        for i,old_state in enumerate(node_states):
            new_state_sequence[i] = new_indices[old_state]

        self.hidden_states = len(new_states)

        # print(self.hidden_states)

        new_state_sample_log_odds = np.zeros((self.hidden_states,self.total_samples))

        for old_index,state in enumerate(self.state_sample_log_odds):
            if old_index in new_indices:
                new_state_sample_log_odds[new_indices[old_index]] = state

        self.state_sample_log_odds = new_state_sample_log_odds

        # print(new_state_sequence)

        return new_state_sequence

    def recompute_state_masks(self,node_states):

        print("Computing State Masks")

        new_states = self.hidden_states

        new_state_masks = np.zeros((new_states,node_states.shape[0]),dtype=bool)

        for state in range(new_states):
            new_state_masks[state] = node_states == state

        # print(new_state_masks.shape)

        return new_state_masks


    def recompute_state_sample_log_odds(self,states,samples,alpha_e,beta_e,state_masks,state_sample_log_odds,divergence_l,divergence_r):

        print("Recomputing Sample Log Odds")

        new_state_sample_log_odds = np.zeros((states,samples))
        new_raw_sample_odds = np.zeros((states,samples))

        sample_totals = np.sum(divergence_l,axis=0) + np.sum(divergence_r,axis=0)

        sample_totals = sample_totals.astype(dtype=float)

        # print(new_state_sample_log_odds.shape)

        for i,state_mask in list(enumerate(state_masks))[1:]:

            # print("SAMPLE LOG ODDS DEBUG")
            # print(state_mask.shape)

            ## First we want:
            ##  -only nodes in state
            ##  -left and right mask each
            ##      -This matrix is node x sample, true if left/right

            l = divergence_l[state_mask]
            r = divergence_r[state_mask]

            # print(l.shape)
            # print(r.shape)

            # print(i)
            # print(l.shape)
            # print(r.shape)

            ## We want to figure out whether to use the right or the left split of the node:

            ## First take each sample mask and use it to select log odds from state sample log odds

            state_sample_log_tile = np.tile(state_sample_log_odds[i],(np.sum(state_mask),1))

            # print(state_sample_log_tile.shape)

            # print(state_sample_log_tile.shape)

            left_log_odds = np.zeros(l.shape)
            left_log_odds[l] = state_sample_log_tile[l]

            right_log_odds = np.zeros(r.shape)
            right_log_odds[r] = state_sample_log_tile[r]

            ## Next we sum the log odds to obtain total log odds of the fit of each side of the divergence
            ## to the state model

            left_fit = np.sum(left_log_odds,axis=1)
            right_fit = np.sum(right_log_odds,axis=1)

            # print(left_fit.shape)
            # print(right_fit.shape)

            ## If right fit is better than left fit, we would like to flip

            flip = right_fit > left_fit

            # print(flip.shape)

            ## Next we want to figure out the totals going left and right

            l_total = np.sum(l[np.logical_not(flip)],axis=0) + np.sum(r[flip],axis=0)
            r_total = np.sum(r[np.logical_not(flip)],axis=0) + np.sum(l[flip],axis=0)

            ## L total here is a sample x 1 matrix that is the sum of all nodes present in the state that also had that sample go left
            ## R total here is a sample x 1 matrix that had the samples go the other way

            # print(l_total.shape)
            # print(r_total.shape)

            l_total = l_total.astype(dtype=float)
            r_total = r_total.astype(dtype=float)

            l_total = l_total + alpha_e

            r_total = r_total + beta_e

            state_total = l_total + r_total

            # ext_l = sample_totals - l_total + (2 * alpha_e)
            ext_total = sample_totals - state_total + (2* beta_e) / states

            ## The new log odds are now ready to be computed:

            # print(l_total)
            # print(state_total)

            # print(ext_l)
            # print(ext_total)

            # new_state_sample_log_odds[i] = np.log2((l_total/state_total) / (ext_l/ext_total))

            # new_state_sample_log_odds[i] = np.log2(l_total/r_total)

            new_state_sample_log_odds[i] = np.log2(l_total + ext_total/r_total + ext_total)
            new_raw_sample_odds[i] = np.log2(l_total/r_total)
            # posterior_probability = (l_total/(l_total + r_total))
            # posterior_odds = (posterior_probability / (1 - posterior_probability))
            # new_state_sample_log_odds[i] = np.log2(posterior_odds)

        # print(new_state_sample_log_odds)

        return new_state_sample_log_odds,new_raw_sample_odds

    def recompute_transition_counts(self,live_mask,oracle_indicator_l,oracle_indicator_r,states,node_states,child_state_l,child_state_r):

        print("Recomputing Transition Counts")

        new_transition_counts = np.zeros((states,states))

        transition_mask_l = np.logical_and(live_mask,np.logical_not(oracle_indicator_l))
        transition_mask_r = np.logical_and(live_mask,np.logical_not(oracle_indicator_r))

        # transition_mask = live_mask

        for ps,csl in zip(node_states[transition_mask_l],child_state_l[transition_mask_l]):
            # print(csl)
            # print(ps)
            new_transition_counts[csl,ps] += 1

        for ps,csr in zip(node_states[transition_mask_r],child_state_r[transition_mask_r]):
            # print(csr)
            # print(ps)
            new_transition_counts[csr,ps] += 1

        # print(new_transition_counts)

        return new_transition_counts

    def recompute_oracle_transition_matrix(self,states,oracle_indicator_l,oracle_indicator_r,node_states,child_state_l,child_state_r):

        print("Recomputing oracle transition count")

        new_oracle_transitions = np.zeros((states,states))

        for ps,csl in zip(node_states[oracle_indicator_l],child_state_l[oracle_indicator_l]):
            new_oracle_transitions[csl,ps] += 1

        for ps,csr in zip(node_states[oracle_indicator_r],child_state_r[oracle_indicator_r]):
            new_oracle_transitions[csr,ps] += 1

        new_oracle_transitions[0] = 0

        # print(new_oracle_transitions)

        return new_oracle_transitions


    def recompute_oracle_transition_counts(self,oracle_transition_matrix):

        print("Recomputing oracle transition count")

        new_oracle_transitions = np.ones(oracle_transition_matrix.shape[0])

        new_oracle_transitions += np.sum(oracle_transition_matrix,axis=0)

        new_oracle_transitions[0] = 0

        # print(new_oracle_transitions)

        return new_oracle_transitions

    # def state_log_odds_given_divergence(self,divergence_l,divergence_r,state_sample_log_odds):
    #
    #     print("Computing state log odds | divergence")
    #
    #     state_log_odds = np.zeros((self.hidden_states,self.total_nodes))
    #
    #     l = np.zeros((self.total_nodes,self.total_samples))
    #     r = np.zeros((self.total_nodes,self.total_samples))
    #
    #     for i,state in enumerate(state_sample_log_odds):
    #
    #         tile_odds = np.tile(state,(self.total_nodes,1))
    #
    #         # print(tile_odds.shape)
    #
    #         l[:,:] = 0
    #         r[:,:] = 0
    #
    #         l[divergence_l] = tile_odds[divergence_l]
    #         r[divergence_r] = tile_odds[divergence_r]
    #
    #         l_state_odds = np.sum(l,axis=1)
    #         r_state_odds = np.sum(r,axis=1)
    #
    #         l_combined = l_state_odds - r_state_odds
    #         r_combined = r_state_odds - l_state_odds
    #
    #         state_log_odds[i] = np.maximum(l_combined,r_combined)
    #
    #     # print(state_log_odds)
    #
    #     return state_log_odds

    def compute_state_log_odds_given_divergence(self,divergence_l,divergence_r,state_sample_log_odds):

        print("Computing state log odds | divergence")

        node_output = self.pool.map(IHMM.node_state_log_odds_given_divergence,zip(divergence_l,divergence_r,repeat(state_sample_log_odds)))

        # print(node_output)
        # print(np.array(node_output).shape)

        return np.array(node_output).T

    def node_state_log_odds_given_divergence(task):

        dl,dr,state_sample_log_odds = task

        l = np.sum(state_sample_log_odds[:,dl],axis=1)
        r = np.sum(state_sample_log_odds[:,dr],axis=1)

        f = l-r
        r = r-l

        return np.maximum(f,r)

    def compute_state_log_odds_given_child_direct_transition(self,beta,transition_counts,node_child_states):

        ## Here we have to start considering the potential fact that an oracle may be sampled
        ## Since this is the first transition, for simplicity we will simply compute the odds of a direct transition and an oracle transition of any kind

        padded_transition_counts = np.zeros((transition_counts.shape[0],transition_counts.shape[1]+1))
        padded_transition_counts[:,:-1] += transition_counts
        padded_transition_counts[:,-1] += beta

        # print("Transition odds debug")
        # print(padded_transition_counts)

        total_transitions = np.sum(padded_transition_counts,axis=1)

        counter_odds = np.tile(total_transitions,(padded_transition_counts.shape[1],1)).T
        counter_odds -= padded_transition_counts

        transition_odds = padded_transition_counts.astype(dtype=float) / counter_odds.astype(dtype=float)

        # print(transition_odds)

        node_state_odds = transition_odds[node_child_states].T

        return node_state_odds

    def sample_states(self,live_mask,state_log_odds):

        print("Sampling states")

        live_nodes = np.sum(live_mask)

        state_raw_odds = np.exp2(state_log_odds)
        #
        # print("State Raw Odds")
        # print(state_raw_odds)

        descending_odds = np.cumsum(state_raw_odds,axis=0)

        draws = np.random.rand(live_nodes) * descending_odds[-1,live_mask]

        # print("descending_odds")
        # print(descending_odds)
        #
        # print("draws")
        # print(draws)

        draw_index = np.sum(descending_odds[:,live_mask] < np.tile(draws,(descending_odds.shape[0],1)),axis=0) + 1

        new_state_indicator = draw_index >= descending_odds.shape[0]-1

        return draw_index, new_state_indicator

    def compute_state_odds_given_oracle(self,gamma,nodes,oracle_transition_counts):

        print("Computing oracle odds")

        print(oracle_transition_counts)

        odds = np.zeros(oracle_transition_counts.shape[0]+1)
        odds[:-1] = oracle_transition_counts
        odds[-1] = gamma


        counter_odds = np.sum(odds) * np.ones(odds.shape)
        counter_odds -= odds

        fractional_odds = odds/counter_odds

        ## Here we tile the odds across all nodes, because they are uniform
        fractional_odds = np.tile(fractional_odds,(nodes,1)).T

        return fractional_odds

    def sample_oracle_indicator(self,node_state,direct_state_odds_l,direct_state_odds_r,oracle_state_odds_l,oracle_state_odds_r):

        # print("Oracle sampler debug")

        state_mask = np.equal(np.tile(np.arange(direct_state_odds_l.shape[0]),(direct_state_odds_l.shape[1],1)).T,np.tile(node_state,(direct_state_odds_l.shape[0],1)))

        # print(node_state)
        # print(np.sum(state_mask,axis=0))
        # print(np.sum(state_mask,axis=1))

        direct_state_odds_l = direct_state_odds_l[state_mask]
        direct_state_odds_r = direct_state_odds_r[state_mask]

        # print(direct_state_odds_l.shape)
        # print(direct_state_odds_r.shape)

        oracle_state_odds_l = oracle_state_odds_l[state_mask]
        oracle_state_odds_r = oracle_state_odds_r[state_mask]

        oracle_probability_l = (oracle_state_odds_l / (oracle_state_odds_l + direct_state_odds_l))
        oracle_probability_r = (oracle_state_odds_r / (oracle_state_odds_r + direct_state_odds_r))

        oracle_indicator_l = np.random.rand(oracle_probability_l.shape[0]) > oracle_probability_l
        oracle_indicator_r = np.random.rand(oracle_probability_r.shape[0]) > oracle_probability_r

        return oracle_indicator_l,oracle_indicator_r


    def generate_new_states(self,states,new_state_mask):

        print("Labeling new states")
        print(f"Label:{states+1}")
        # total_new_states = np.sum(new_state_mask)
        # return np.arange(states,states+total_new_states)

        return states + 1

    def lr_finite(self,state):
        return expit(self.state_raw_sample_odds[state])

    def state_node_odds(self,state):

        state_mask = self.state_masks[state]

        return self.state_log_odds[state,state_mask]

    def pad_root_transitions(self):
        for node in self.nodes:
            if node.parent is None:
                self.transition_counts[node.index,0] += 1

    def most_likely_parent_to_child(self):

        self.pad_root_transitions()

        most_likely_transition_matrix = np.zeros((self.hidden_states,self.hidden_states))

        for hidden_state,transitions in enumerate(self.transition_counts):

            most_likely_parent = np.argmax(transitions)
            most_likely_transition_matrix[hidden_state,most_likely_parent] += 1

        return most_likely_transition_matrix.T



    #
    #
    #
    # def raw_transition_matrix(self):
    #
    #     states = self.hidden_states
    #
    #     new_transition_counts = np.zeros((states,states))
    #
    #     # transition_mask = np.logical_and(live_mask,np.logical_not(oracle_indicator))
    #
    #     transition_mask = self.live_mask
    #
    #     for ps,csl in zip(self.node_states[transition_mask],self.child_state_l[transition_mask]):
    #         # print(csl)
    #         # print(ps)
    #         new_transition_counts[csl,ps] += 1
    #
    #     for ps,csr in zip(self.node_states[transition_mask],self.child_state_r[transition_mask]):
    #         # print(csr)
    #         # print(ps)
    #         new_transition_counts[csr,ps] += 1
    #
    #     print(new_transition_counts)
    #
    #     return new_transition_counts



    #
    # def resample_node_states(self,transition_odds,sample_odds,node_states,node_divergences,children_l,children_r):
    #
    #     state_log_odds = np.zeros((self.hidden_states,self.total_nodes))
    #
    #     state_log_odds += self.state_log_odds_given_child()







##
