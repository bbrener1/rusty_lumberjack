{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOTE TO SELF ######\n",
    "# Linear behavior global vs braid\n",
    "\n",
    "# SPC25 IS GOOD EXAMPLE\n",
    "# Cenpe good\n",
    "# Mgst3 maybe\n",
    "# Irf8 maybe\n",
    "# Ctsg is marginal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# mpl.rcParams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# COLOR = 'white'\n",
    "# mpl.rcParams['text.color'] = COLOR\n",
    "# mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "# mpl.rcParams['xtick.color'] = COLOR\n",
    "# mpl.rcParams['ytick.color'] = COLOR\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "\n",
    "# import fancyimpute as fi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import variation\n",
    "from math import isnan\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import lumberjack\n",
    "import tree_reader as tr\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts = np.loadtxt('/Users/boris/taylor/johnston_retina/single_cell/dmel-retina-scRNA/exploration/2018.07.19_Scanpy/log_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/johnston_retina/single_cell/dmel-retina-scRNA/exploration/2018.07.19_Scanpy/header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/work/johnston_log_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/work/johnston_header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/aging_sc/var_filtered_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/aging_sc/var_filtered_header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/fan_tendon/log_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/fan_tendon/header.txt\",dtype=str)\n",
    "\n",
    "counts = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/raw_data/vision_sc/nesterowa_counts.txt')\n",
    "header = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/raw_data/vision_sc/nesterowa_gene_header.txt',dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/nelmari/nc_filtered_log.txt')\n",
    "# header = np.loadtxt('/Users/boris/taylor/nelmari/gene_header_filtered.txt',dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/testing/iris.trunc')\n",
    "# header = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/testing/iris.features',dtype=str)\n",
    "\n",
    "# feature_sort = dendrogram(linkage(counts.T,metric='correlation',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# counts = counts[cell_sort].T[feature_sort].T\n",
    "# counts = counts.T[feature_sort].T\n",
    "# header = header[feature_sort]\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Gene Expression Unsorted\",fontsize=20)\n",
    "# plt.imshow(counts,aspect='auto')\n",
    "# plt.xlabel(\"Genes\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# cell_sort = dendrogram(linkage(counts,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Gene Expression, Agglomerative\",fontsize=20)\n",
    "# plt.imshow(counts[cell_sort],aspect='auto')\n",
    "# plt.xlabel(\"Genes\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Frequency of Mean Gene Expression Values, Mouse Blood Cells\")\n",
    "# plt.xlabel(\"Mean Expression (log TPM)\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.hist(np.mean(counts,axis=0),bins=50,log=True)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Frequency of Individual Expression Values, Mouse Blood Cells\")\n",
    "# plt.xlabel(\"Mean Expression (log TPM)\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.hist(counts.flatten(),bins=50,log=True)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# print(np.mean(counts,axis=0).shape)\n",
    "# print(header.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"./prediction/\"\n",
    "raw_text_out = open(output_directory + str(\"evaluation.txt\"),mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_mask = np.random.random(counts.shape[0]) > .1\n",
    "testing_mask = np.logical_not(training_mask)\n",
    "\n",
    "training_counts = counts[training_mask]\n",
    "testing_counts = counts[testing_mask]\n",
    "\n",
    "# training_counts = counts\n",
    "# testing_counts = counts\n",
    "\n",
    "# forest = tr.Forest.reconstitute('./forest_nelmari')\n",
    "\n",
    "# forest = tr.Forest.reconstitute('./forest_vision')\n",
    "# forest = tr.Forest.reconstitute('./forest_vision_l1')\n",
    "# forest = tr.Forest.reconstitute('./forest_vision_l2')\n",
    "\n",
    "\n",
    "# forest = tr.Forest.reconstitute('./forest_johnston_braid')\n",
    "\n",
    "# forest = tr.Forest.load(\"../testing/nelmari/\",input='../../../../../nelmari/nc_filtered_log.txt',output='../../../../../nelmari/nc_filtered_log.txt')\n",
    "# forest = tr.Forest.load(\"../testing/nesterowa_forest/\",input=\"../../work/nesterowa_counts.txt\",output=\"../../work/nesterowa_counts.txt\")\n",
    "# forest = tr.Forest.load(\"../testing/johnston_forest/\",input=\"../../work/johnston_log_counts.txt\",output=\"../../work/johnston_log_counts.txt\")\n",
    "\n",
    "# counts = sklearn.preprocessing.scale(counts)\n",
    "\n",
    "forest = lumberjack.fit(training_counts,test_counts=testing_counts,trees=100,dispersion_mode=\"ssme\",norm=\"l2\",drop='none',sfr=1,in_feature_subsample=1000,out_feature_subsample=1000,sample_subsample=200,depth=5,leaves=20,header=header)\n",
    "\n",
    "# forest.weigh_leaves()\n",
    "\n",
    "training_counts = forest.output\n",
    "testing_counts = forest.test\n",
    "\n",
    "# predicted = forest.predict_matrix(testing_counts)\n",
    "\n",
    "# true_counts = testing_counts\n",
    "\n",
    "subsampling = 1\n",
    "\n",
    "# mask = np.loadtxt('./testing/holdout_mask_counts.txt')\n",
    "\n",
    "# held_out_counts = np.loadtxt('./testing/held_out_counts.txt')\n",
    "\n",
    "#2 trees at 2:17\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.backup('./forest_johnston_ihmm')\n",
    "# forest.backup('./forest_johnston_ssme')\n",
    "# forest.backup('./forest_johnston_flat_sme')\n",
    "# forest.backup('./forest_johnston_var')\n",
    "# forest.backup('./forest_fan_ssme')\n",
    "\n",
    "# forest.backup('./forest_johnston_braid')\n",
    "# forest.backup('./forest_nelmari')\n",
    "\n",
    "# forest.backup('./forest_vision_l1')\n",
    "# forest.backup('./forest_vision_l2')\n",
    "forest.backup('./forest_vision_lrg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional adjustment to truncate lower-expressing genes.\n",
    "# expression_level_mask = np.mean(true_counts,axis=0) > 1\n",
    "# true_counts = true_counts.T[expression_level_mask].T\n",
    "# predicted = predicted.T[expression_level_mask].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# raw_text_out.write(\"=================================================\\n\")\n",
    "# raw_text_out.write(\"Basic evaluation: \\n\")\n",
    "\n",
    "# raw_text_out.write(\"Pearson R\\n\")\n",
    "# raw_text_out.write(str(pearsonr(predicted.flatten(),true_counts.flatten())) + \"\\n\")\n",
    "\n",
    "# raw_text_out.write(\"MSE\\n\")\n",
    "# raw_text_out.write(str(np.mean((predicted.flatten() - true_counts.flatten()) ** 2)) + \"\\n\")\n",
    "\n",
    "# raw_text_out.write(\"MAE\\n\")\n",
    "# raw_text_out.write(str(np.mean(np.abs(predicted.flatten() - true_counts.flatten()))) + \"\\n\")\n",
    "\n",
    "\n",
    "# raw_text_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_counts = forest.test\n",
    "\n",
    "# prediction = forest.predict_matrix(test_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sys.path.append(\"/Users/boris/haxx/python/smooth_density_graph/\")\n",
    "# import smooth_density_graph as sdg\n",
    "\n",
    "# forest.reset_clusters()\n",
    "# from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "\n",
    "# feature_sort = dendrogram(linkage(counts.T,metric='correlation',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# counts = forest.output\n",
    "\n",
    "# encoding = forest.node_sample_encoding(forest.leaves())\n",
    "# print(encoding.shape)\n",
    "\n",
    "# print(np.sum(np.sum(encoding,axis=1) == 0))\n",
    "# cell_sort = dendrogram(linkage(encoding,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# leaf_sort = dendrogram(linkage(encoding.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# # feature_sort = dendrogram(linkage(forest.output.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# # feature_sort = np.argsort(np.var(forest.output,axis=0))\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# # plt.imshow(encoding,aspect='auto',cmap='binary')\n",
    "# plt.imshow(encoding[cell_sort].T[leaf_sort].T,aspect='auto',cmap='binary')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # print(np.sum(np.isnan(encoding).flatten()))\n",
    "\n",
    "# cell_clusterings = forest.cluster_samples_encoding(distance='cos',k=10,steps=50,override=False,verbose=True)\n",
    "# # cell_clusterings = forest.cluster_samples_simple(pca=True,subsample=1400,distance='cos',k=10,steps=50,override=True,verbose=True)\n",
    "# leaf_clusterings = forest.cluster_leaf_samples(distance='cos',k=10,steps=50,override=False,verbose=True)\n",
    "\n",
    "# cell_order = np.argsort(cell_clusterings)\n",
    "# leaf_order = np.argsort(leaf_clusterings)\n",
    "\n",
    "# # clustered_counts = forest.output[cell_order].T[feature_sort].T\n",
    "# clustered_counts = counts[cell_order].T[feature_sort].T\n",
    "# clustered_encoding = encoding[cell_order].T[leaf_order].T\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Gene Expression, Forest Clustering\",fontsize=20)\n",
    "# plt.imshow(clustered_counts,aspect='auto')\n",
    "# plt.xlabel(\"Genes\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Node Organization, Forest Clustering\",fontsize=20)\n",
    "# plt.imshow(clustered_encoding,aspect='auto',cmap='binary')\n",
    "# plt.xlabel(\"Leaves\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"===================\")\n",
    "\n",
    "# for cluster in forest.sample_clusters:\n",
    "#     print(len(cluster.samples))\n",
    "\n",
    "# print(\"===================\")\n",
    "\n",
    "# for cluster in forest.leaf_clusters:\n",
    "#     print(len(cluster.nodes))\n",
    "\n",
    "# print(\"===================\")\n",
    "# print(\"===================\")\n",
    "# print(\"===================\")\n",
    "# print(len(forest.sample_clusters))\n",
    "# print(len(forest.leaf_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_encoding = forest.node_sample_encoding(forest.nodes())\n",
    "\n",
    "# total_cell_sort = dendrogram(linkage(total_encoding,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# node_sort = dendrogram(linkage(total_encoding.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(total_encoding[total_cell_sort].T[node_sort].T,aspect='auto',cmap='binary')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(len(forest.sample_clusters))\n",
    "# print(len(forest.leaf_clusters))\n",
    "# matrix = forest.raw_prediction_matrix(forest.nodes())\n",
    "# # print(matrix.shape)\n",
    "\n",
    "# leaf_sort = dendrogram(linkage(matrix,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# feature_sort = dendrogram(linkage(matrix.T,metric='euclidean',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(matrix[leaf_sort].T[feature_sort].T,aspect='auto',cmap='binary')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# split_sort = np.argsort(forest.split_labels)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(matrix[split_sort].T[feature_sort].T,aspect='auto',cmap='binary')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#########################################################\n",
    "#########################################################\n",
    "##################                     ##################\n",
    "##################   ##   ##   ####    ##################\n",
    "##################    ## ##   ##  ##   ##################\n",
    "##################     ###    ##  ##   ##################\n",
    "##################     ##     ##  ##   ##################\n",
    "##################    ##       ####    ##################\n",
    "##################                     ##################\n",
    "#########################################################\n",
    "#########################################################\n",
    "#########################################################\n",
    "\n",
    "\n",
    "# forest.reset_clusters()\n",
    "# forest.interpret_splits(depth=4,k=10,mode='sample',steps=20,reduction_metric='jaccard',distance='cosine',override=False,verbose=True)\n",
    "# split_order = np.argsort(forest.split_labels)\n",
    "# print(np.sum(forest.split_labels < 7))\n",
    "# print(np.sum(forest.split_labels < 8))\n",
    "# print(np.sum(forest.split_labels < 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tree = forest.most_likely_tree(depth=5)\n",
    "# tree\n",
    "\n",
    "# tree = forest.maximum_spanning_tree(depth=4)\n",
    "# tree\n",
    "\n",
    "# transitions = forest.split_cluster_transition_matrix()\n",
    "# transitions[:,88]\n",
    "\n",
    "# forest.likely_tree = forest.maximum_tree\n",
    "\n",
    "# tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "# encoding = forest.node_sample_encoding(forest.nodes(depth=4))\n",
    "\n",
    "# jaccard_distances = squareform(pdist(encoding.T,metric='jaccard'))\n",
    "# cell_ordering = dendrogram(linkage(encoding,metric='jaccard',method='average'),no_plot=True)['leaves']\n",
    "# node_ordering = dendrogram(linkage(encoding.T,metric='jaccard',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(jaccard_distances[node_ordering].T[node_ordering],aspect='auto')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(encoding[cell_ordering].T[node_ordering],aspect='auto')\n",
    "# # plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forest.coordinates(override=False)\n",
    "# forest.tsne_encoding(override=True)\n",
    "# forest.plot_split_clusters()\n",
    "\n",
    "# feature = \"Cd34\"\n",
    "# coordinates = forest.coordinates(override=False,no_plot=True,pca=True)\n",
    "# fi = forest.truth_dictionary.feature_dictionary[feature]\n",
    "# plt.figure()\n",
    "# plt.title(f\"Expression of {feature}\")\n",
    "# plt.scatter(coordinates[:,0],coordinates[:,1],c=forest.output[:,fi],s=10)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# braid = forest.trees[0].plot()\n",
    "# print(braid.compound_split)\n",
    "# print(np.sum(np.array(braid.compound_values) < braid.compound_split))\n",
    "# print(len(forest.trees[0].root.children[0].samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forest.cluster_samples_encoding(k=10,steps=50,override=False,verbose=True)\n",
    "# forest.cluster_samples_simple(pca=True,k=10,steps=50,override=True,verbose=True)\n",
    "# forest.plot_cell_clusters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forest.leaf_clusters[0].ranked_mean_gains()\n",
    "# forest.leaf_clusters[0].prerequisite_frequency()\n",
    "# forest.leaf_clusters[3].biological_cluster_summary()\n",
    "# print(forest.weighted_node_vector_prediction(forest.leaf_clusters[0].nodes))\n",
    "# print(forest.weighted_node_vector_prediction([forest.prototype.root]))\n",
    "# forest.tsne_encoding(override=True)\n",
    "# forest.cluster_leaf_samples(k=10,steps=50,override=False,verbose=True)\n",
    "# forest.cluster_samples_encoding(k=10,steps=50,override=True,verbose=True)\n",
    "# forest.cluster_samples_simple(pca=False,k=10,steps=50,override=False,verbose=True)\n",
    "# forest.plot_cell_clusters()\n",
    "# forest.plot_cell_clusters(colorize=False)\n",
    "# print(len(forest.sample_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.decomposition import PCA\n",
    "# forest.trees[0].root.child_clusters\n",
    "# nodes,labels,encoding = forest.cluster_divergence(k=10,distance='manhattan',verbose=True,steps=10,auto=True)\n",
    "# print(len(forest.divergence_clusters[4].nodes[2].samples))\n",
    "\n",
    "# encoding_ordering = np.argsort(labels)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(encoding,aspect='auto')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(encoding[encoding_ordering],aspect='auto')\n",
    "# plt.show()\n",
    "\n",
    "# tc = TSNE().fit_transform(forest.counts)\n",
    "\n",
    "\n",
    "# tc = forest.tsne(pca=True,override=False,no_plot=True)\n",
    "\n",
    "# tc = PCA(n_components=2).fit_transform(forest.output)\n",
    "\n",
    "# tc = forest.coordinates(no_plot=True)\n",
    "\n",
    "# for split_cluster in forest.split_clusters:\n",
    "#     print(split_cluster.id)\n",
    "#     try:\n",
    "#         print(sorted(list(split_cluster.braid_features().items()),key=lambda x:x[1])[::-1])\n",
    "# #         print(list(split_cluster.braid_features().items()))\n",
    "#     except:\n",
    "#         pass\n",
    "#     split_cluster.plot_cell_counts()\n",
    "\n",
    "#     sister_color = split_cluster.sister_scores()\n",
    "\n",
    "#     f = plt.figure(figsize=(15,10))\n",
    "#     plt.title(\"Sister Split\")\n",
    "#     plt.scatter(tc[:,0],tc[:,1],c=sister_color,cmap='bwr',vmin=max(sister_color)*-1)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     braid_color = split_cluster.braid_scores()\n",
    "    \n",
    "#     f = plt.figure(figsize=(15,10))\n",
    "#     plt.scatter(tc[:,0],tc[:,1],c=braid_color,cmap='bwr',vmin=max(braid_color)*-1)\n",
    "# #     plt.scatter(tc[:,0],tc[:,1],c=braid_color,cmap='bwr')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "\n",
    "#     braids = split_cluster.braids()\n",
    "#     mean_split = np.mean([b.compound_split for b in braids])\n",
    "\n",
    "#     print(mean_split)\n",
    "    \n",
    "# forest.split_clusters[0].plot_braid_vectors(figure=f)\n",
    "\n",
    "# for leaf_cluster in forest.leaf_clusters:\n",
    "#     print(leaf_cluster.id)\n",
    "#     leaf_cluster.plot_cell_counts()\n",
    "    \n",
    "# forest.divergence_clusters[x].plot_cell_counts()\n",
    "# print([len(dc.nodes) for dc in forest.divergence_clusters])\n",
    "# print([n.level for n in forest.divergence_clusters[x].nodes])\n",
    "# print([n.feature for n in forest.divergence_clusters[x].nodes])\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.hist([n.feature for n in forest.divergence_clusters[x].nodes])\n",
    "# plt.xticks(rotation='vertical')\n",
    "# plt.show()\n",
    "\n",
    "# (positive_vector,positive_features),(negative_vector,negative_features) = forest.split_clusters[0].braid_vectors()\n",
    "\n",
    "# cc = forest.split_clusters[0].coordinates(coordinates=tc)\n",
    "\n",
    "# f,v = forest.plot_manifold(depth=3)\n",
    "\n",
    "# f.savefig(\"../work/temp.delete.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,20))\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# forest.split_clusters[18].up_down_panel(ax,6,mask_fraction=1)\n",
    "# plt.show()\n",
    "# forest.split_clusters[3].biological_cluster_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig = forest.plot_tree_summary(n=6,type=\"ud\",primary=True,secondary=False,figsize=(80,40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forest.plot_manifold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for split_cluster in forest.split_clusters:\n",
    "#     print(split_cluster.id)\n",
    "#     print(list(split_cluster.braid_features().items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(forest.trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# print(forest.trees[0].root.child_clusters)\n",
    "# print([l.cluster for l in forest.trees[0].root.leaves()])\n",
    "# forest.leaves()[0].cluster\n",
    "# forest.leaves()[0].find_cluster_divergence(1889).child_clusters\n",
    "\n",
    "\n",
    "# distance_mtx = np.zeros((len(forest.leaf_clusters),len(forest.leaf_clusters)))\n",
    "\n",
    "# for i,c1 in enumerate(forest.leaf_clusters):\n",
    "#     for j,c2 in enumerate(forest.leaf_clusters):\n",
    "        \n",
    "#         _nodes,distances = forest.find_leaf_cluster_divergence(c1.id,c2.id)\n",
    "        \n",
    "#         md = np.mean(distances)\n",
    "#         if np.isnan(md):\n",
    "#             md = 5 + random.random()\n",
    "#         distance_mtx[i,j] = md\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# cluster_sort = dendrogram(linkage(distance_mtx,metric='cos',method='average'),no_plot=False)['leaves']\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(distance_mtx[cluster_sort].T[cluster_sort].T,aspect='auto')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cluster_matrix = np.zeros((len(forest.sample_clusters),len(forest.leaf_clusters)))\n",
    "# for i,sample_cluster in enumerate(forest.sample_clusters):\n",
    "#     leaf_cluster_frequency = sample_cluster.leaf_cluster_frequency(plot=False)[1]\n",
    "#     for j,lcf in enumerate(leaf_cluster_frequency):\n",
    "#         cluster_matrix[i,j] = lcf\n",
    "        \n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.title(\"Occurrence of Leaf Clusters in Cell Clusters\",fontsize=30)\n",
    "# plt.imshow(np.log(cluster_matrix+1),aspect='auto')\n",
    "# plt.xlabel(\"Leaf Clusters\",fontsize=24)\n",
    "# plt.ylabel(\"Cell Clusters\",fontsize=24)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# vertical_order = dendrogram(linkage(cluster_matrix,metric='correlation'),no_plot=True)['leaves']\n",
    "# horizontal_order = dendrogram(linkage(cluster_matrix.T,metric='correlation'),no_plot=True)['leaves']\n",
    "\n",
    "# rearranged_sample_ticks = np.arange(len(forest.sample_clusters))[vertical_order]\n",
    "# rearranged_leaf_ticks = np.arange(len(forest.leaf_clusters))[horizontal_order]\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.title(\"Occurrence of Leaf Clusters in Cell Clusters\",fontsize=30)\n",
    "# plt.imshow(np.log(cluster_matrix+1)[vertical_order].T[horizontal_order].T,aspect='auto')\n",
    "# plt.xlabel(\"Leaf Clusters\",fontsize=24)\n",
    "# plt.ylabel(\"Cell Clusters\",fontsize=24)\n",
    "# plt.xticks(np.arange(len(rearranged_leaf_ticks)),rearranged_leaf_ticks)\n",
    "# plt.yticks(np.arange(len(rearranged_sample_ticks)),rearranged_sample_ticks)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.prereq_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# dendrogram(linkage(forest.sample_cluster_coordinate_matrix()),labels=[cluster.id for cluster in forest.sample_clusters])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.sample_clusters[4].leaf_cluster_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.leaf_clusters[3].biological_cluster_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.leaf_clusters[0].average_prereq_freq_level()\n",
    "# forest.leaf_clusters[1].average_prereq_freq_level()\n",
    "# forest.leaf_clusters[6].average_prereq_freq_level()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cluster import DBSCAN\n",
    "# from hdbscan import HDBSCAN\n",
    "\n",
    "# encoding = forest.node_sample_encoding(forest.leaves())\n",
    "\n",
    "# d_cell_clusters = HDBSCAN(min_samples=5).fit_predict(encoding)\n",
    "# d_leaf_clusters = HDBSCAN(min_samples=5).fit_predict(encoding.T)\n",
    "\n",
    "# d_cell_ordering = np.argsort(d_cell_clusters)\n",
    "# d_leaf_ordering = np.argsort(d_leaf_clusters)\n",
    "# # d_leaf_ordering = dendrogram(linkage(encoding.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20,8))\n",
    "# plt.imshow(encoding[d_cell_ordering].T[d_leaf_ordering].T,aspect='auto',cmap='binary')\n",
    "# plt.show()\n",
    "\n",
    "# gain_matrix = forest.local_gain_matrix(forest.nodes())\n",
    "\n",
    "# d_leaf_clusters = HDBSCAN(min_samples=5).fit_predict(gain_matrix.T)\n",
    "# d_leaf_ordering = np.argsort(d_leaf_clusters)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(gain_matrix[feature_sort].T[d_leaf_ordering],aspect='auto',)\n",
    "# plt.show()\n",
    "\n",
    "# print(set(d_cell_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_p_cell_clusters = HDBSCAN(min_samples=5).fit_predict(training_counts)\n",
    "# d_p_feature_clusters = HDBSCAN(min_samples=5).fit_predict(training_counts.T)\n",
    "\n",
    "# d_p_cell_ordering = np.argsort(d_p_cell_clusters)\n",
    "# # d_p_feature_ordering = np.argsort(d_p_feature_clusters)\n",
    "\n",
    "# plt.figure(figsize=(20,8))\n",
    "# plt.imshow(training_counts[d_p_cell_ordering],aspect='auto',cmap='binary')\n",
    "# plt.show()\n",
    "\n",
    "# print(set(d_p_cell_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # t_coordinates = TSNE().fit_transform(forest.node_sample_encoding(forest.leaves()))\n",
    "# t_coordinates = TSNE().fit_transform(forest.counts)\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cells Transformed by TSNE (Arbitrary Units)\",fontsize=20)\n",
    "# plt.scatter(t_coordinates[:,0],t_coordinates[:,1],s=.1)\n",
    "# plt.show()\n",
    "\n",
    "# # for cluster in set(cell_clusters):\n",
    "# #     print(np.sum(np.array(cell_clusters) == cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sys.path.append(\"/Users/boris/haxx/python/smooth_density_graph/\")\n",
    "# import smooth_density_graph as sdg\n",
    "\n",
    "# # encoding = forest.node_sample_encoding(forest.leaves())\n",
    "\n",
    "# sdg_encoding_cell_clusters = sdg.fit_predict(encoding,\"fitpredict\",k=5,steps=10,verbose=True)\n",
    "\n",
    "# sdg_encoding_cell_ordering = np.argsort(sdg_cell_clusters)\n",
    "\n",
    "# # sdg_leaf_clusters = sdg.fit_predict(encoding.T,\"fitpredict\",k=5,steps=10,verbose=True)\n",
    "\n",
    "# # sdg_leaf_ordering = np.argsort(sdg_leaf_clusters)\n",
    "\n",
    "# sdg_count_cell_clusters = sdg.fit_predict(forest.counts,\"fitpredict\",k=5,steps=10,verbose=True)\n",
    "\n",
    "# sdg_count_cell_ordering = np.argsort(sdg_count_cell_clusters)\n",
    "\n",
    "# sdg_feature_clusters = sdg.fit_predict(forest.counts.T,\"fitpredict\",k=5,steps=10,verbose=True)\n",
    "\n",
    "# sdg_feature_ordering = np.argsort(sdg_feature_clusters)\n",
    "\n",
    "# tc = forest.tsne(no_plot=True)\n",
    "# density = sdg.fit_predict(forest.node_sample_encoding(forest.leaves()),command=\"density\",k=5,steps=5,verbose=True)\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.scatter(tc[:,0],tc[:,1],c=np.log(density),s=20,alpha=.7,cmap='viridis')\n",
    "# plt.scatter(tc[:,0],tc[:,1],c=density,s=30,alpha=.7,cmap='magma')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Gene Expression, Smooth Gradient Graph\",fontsize=20)\n",
    "# plt.imshow(forest.counts[sdg_encoding_cell_ordering].T[sdg_feature_ordering].T,aspect='auto')\n",
    "# plt.xlabel(\"Genes\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# # plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Gene Expression, Smooth Gradient Graph\",fontsize=20)\n",
    "# plt.imshow(forest.counts[sdg_count_cell_ordering].T[sdg_feature_ordering].T,aspect='auto')\n",
    "# plt.xlabel(\"Genes\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# # plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# k_cell_clusters = KMeans(n_clusters=10).fit_predict(counts)\n",
    "\n",
    "# k_cell_ordering = np.argsort(k_cell_clusters)\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Gene Expression, K-Means\",fontsize=20)\n",
    "# plt.imshow(counts[k_cell_ordering],aspect='auto')\n",
    "# plt.xlabel(\"Genes\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Distribution of Values in Test Counts\")\n",
    "# plt.hist(test_counts.flatten(),bins=50,log=True)\n",
    "# plt.ylim(0,1e6)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Distribution of Values in Prediction\")\n",
    "# plt.hist(prediction.flatten(),bins=50,log=True)\n",
    "# plt.ylim(0,1e6)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Distribution of Error\")\n",
    "# plt.hist((test_counts - prediction).flatten(),bins=50,log=True)\n",
    "# plt.ylim(0,1e6)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.node_sample_encoding(forest.leaves())\n",
    "# forest.leaves()[3].samples\n",
    "# forest.trees[3].plot()\n",
    "# forest.trees[3].tree_movie('./tree_movies/m1/pr1')\n",
    "# forest.trees[4].tree_movie('./tree_movies/m2/pr1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# zero_mask = counts == 0\n",
    "# zero_sum = np.sum(zero_mask,axis=0)\n",
    "# zero_percentrage = zero_sum / counts.shape[0]\n",
    "\n",
    "# plt.figure(\"sparsity_graph\",figsize=(15,10))\n",
    "# plt.title(\"Sparsity of Features in Fly Retina Dataset\",fontsize=20)\n",
    "# plt.hist(zero_percentrage,bins=np.arange(0,1.05,0.05))\n",
    "# plt.xlabel(\"Sparsity (Fraction of values = 0)\",fontsize=15)\n",
    "# plt.ylabel(\"Frequency\",fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_mask = np.random.rand(*test_counts.flatten().shape) < (subsampling/10)\n",
    "\n",
    "# plt.figure(\"general_scatter\")\n",
    "# plt.title(\"True Expression vs Predicted Expression\")\n",
    "# plt.scatter(test_counts.flatten()[random_mask],prediction.flatten()[random_mask],s=1,alpha=.3)\n",
    "# plt.xlabel(\"True Expression\")\n",
    "# plt.ylabel(\"Predicted Expression\")\n",
    "# plt.savefig(output_directory+\"general_scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(\"mae_vs_mean\",figsize=(20,4))\n",
    "# plt.title(\"Mean Absolute Error of Feature Predictions vs Mean Feature Value\")\n",
    "# plt.scatter(np.mean(test_counts,axis=0),np.mean(np.abs(test_counts - prediction), axis=0),s=.1)\n",
    "# plt.plot([0,4],[0,4],c='r')\n",
    "# plt.xlabel(\"Mean Gene Expression\")\n",
    "# plt.ylabel(\"Mean Absolute Error\")\n",
    "# plt.ylim((0,4))\n",
    "# plt.savefig(output_directory+\"mae_vs_mean.png\")\n",
    "\n",
    "# # Calculate MAE\n",
    "# mae = np.mean(np.abs(test_counts - np.tile(np.mean(test_counts,axis=0),(test_counts.shape[0],1))), axis=0)\n",
    "\n",
    "# plt.figure(\"mean_abs_dev_vs_mean\",figsize=(20,4))\n",
    "# plt.title(\"Mean Absolute Deviation of Features vs Expression Level\")\n",
    "# plt.scatter(np.mean(test_counts,axis=0),mae,s=.1)\n",
    "# plt.plot([0,4],[0,4],c='r')\n",
    "# plt.xlabel(\"Mean Gene Expression\")\n",
    "# plt.ylabel(\"Mean Absolute Deviation\")\n",
    "# plt.ylim((0,4))\n",
    "# plt.savefig(output_directory+\"mean_abs_dev_vs_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_mask = np.random.rand(*true_counts.flatten().shape) < subsampling\n",
    "\n",
    "# plt.figure(\"bimodal_scatter_by_mean\",figsize=(6,4))\n",
    "# plt.title(\"Observed Expressions Vs Mean Expression of Feature\")\n",
    "# plt.scatter(np.tile(np.mean(true_counts,axis=0),(true_counts.shape[0],1)).flatten()[random_mask],true_counts.flatten()[random_mask],s=.1,alpha=.1, label=\"Observed Expression\")\n",
    "# # plt.scatter(np.mean(true_counts,axis=0),np.median(true_counts,axis=0),c='r',s=.5, label=\"Mean Expression\")\n",
    "# plt.xlabel(\"Mean Expression\")\n",
    "# plt.ylabel(\"Observed Expression\")\n",
    "# plt.xlim(0,4)\n",
    "# plt.legend()\n",
    "# plt.savefig(output_directory+\"bimodal_scatter_by_mean.png\")\n",
    "\n",
    "# for cluster in forest.sample_clusters:\n",
    "#     cluster_samples = cluster.samples\n",
    "#     cluster_counts = forest.counts[cluster_samples]\n",
    "#     mean_expression = np.mean(cluster_counts,axis=0)\n",
    "#     print(cluster_counts.shape)\n",
    "#     plt.figure()\n",
    "#     plt.scatter(np.tile(mean_expression,(cluster_counts.shape[0],1)).flatten(),cluster_counts.flatten(),s=.1,alpha=.1)\n",
    "#     plt.xlim(0,4)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # print true_counts[:10,:10]\n",
    "\n",
    "# random_mask = np.random.rand(*test_counts.flatten().shape) < subsampling\n",
    "\n",
    "# plt.figure(\"bimodal_scatter_by_mean_predicted\",figsize=(20,4))\n",
    "# plt.title(\"Predicted Values Vs Observed Means\")\n",
    "# plt.scatter(np.tile(np.mean(test_counts,axis=0),(test_counts.shape[0],1)).flatten()[random_mask],prediction.flatten()[random_mask],s=.5,alpha=1,label=\"Expression\")\n",
    "# plt.scatter(np.mean(test_counts,axis=0),np.median(test_counts,axis=0),c='m',s=1,label=\"Medians\")\n",
    "# plt.scatter(np.mean(test_counts,axis=0),np.mean(test_counts,axis=0),c='c',s=1,label=\"Means\")\n",
    "# plt.xlim(0,3)\n",
    "# plt.legend()\n",
    "# plt.savefig(output_directory+\"bimodal_scatter_by_mean_predicted.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_mask = np.random.rand(*test_counts.flatten().shape) < subsampling\n",
    "\n",
    "# plt.figure(\"error_scatter_by_mean\", figsize=(20,4))\n",
    "# plt.title(\"Observed Error vs Observed Mean of Feature\")\n",
    "# plt.scatter(np.tile(np.mean(test_counts,axis=0),(test_counts.shape[0],1)).flatten()[random_mask],(test_counts - prediction).flatten()[random_mask],alpha=.3,s=.3)\n",
    "# plt.xlabel(\"Mean Expression\")\n",
    "# plt.ylabel(\"Predicted Expression\")\n",
    "# plt.savefig(output_directory+\"error_scatter_by_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(\"mean_error_vs_mean\",figsize=(20,4))\n",
    "# plt.title(\"Mean Absolute Error Vs Mean Expression of Gene\")\n",
    "# plt.scatter(np.mean(test_counts,axis=0),np.mean(np.abs(test_counts-prediction),axis=0),s=.5,c=np.std(test_counts,axis=0))\n",
    "# plt.colorbar(label=\"Standard Deviation of Feature\")\n",
    "# # plt.plot([0,3],[0,3])\n",
    "# plt.ylim((0,4))\n",
    "# plt.xlabel(\"Mean Expression\")\n",
    "# plt.ylabel(\"Mean Error\")\n",
    "# plt.savefig(output_directory+\"mean_error_vs_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(\"mean_error_vs_std\",figsize=(4,4))\n",
    "# plt.title(\"Mean Absolute Error Vs Standard Deviation of Gene Expression\")\n",
    "# plt.scatter(np.std(test_counts,axis=0),np.mean(np.abs(test_counts-prediction),axis=0),s=.1)\n",
    "# # plt.colorbar(label=\"Standard Deviation of Feature\")\n",
    "# plt.plot([0,4],[0,4])\n",
    "# plt.ylim((0,4))\n",
    "# plt.xlim((0,4))\n",
    "# plt.xlabel(\"Standard Deviation\")\n",
    "# plt.ylabel(\"Mean Error\")\n",
    "# plt.savefig(output_directory+\"mean_error_vs_std.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# correlations = []\n",
    "\n",
    "# for i in range(test_counts.shape[1]):\n",
    "# #     print(test_counts[:,i])\n",
    "# #     print(prediction[:,i])\n",
    "# #     print(pearsonr(test_counts[:,i],prediction[:,i]))\n",
    "#     correlations.append(pearsonr(test_counts[:,i],prediction[:,i])[0])\n",
    "#     if np.isnan(correlations[-1]):\n",
    "#         correlations[-1] = 0\n",
    "        \n",
    "\n",
    "# print(len(correlations))\n",
    "\n",
    "# plt.figure(\"correlation_vs_mean\",figsize=(20,4))\n",
    "# plt.title(\"Correlation of Predictions to Features per Feature\")\n",
    "# plt.scatter(np.mean(test_counts,axis=0),correlations,s=.3,c=np.std(test_counts,axis=0))\n",
    "# plt.colorbar(label=\"Standard Deviation of Feature\")\n",
    "# plt.xlabel(\"Mean Expression\")\n",
    "# plt.ylabel(\"Prediction Correlation\")\n",
    "# plt.savefig(output_directory+\"correlation_vs_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import linregress\n",
    "\n",
    "# x = np.std(true_counts,axis=0)\n",
    "# y = np.mean(true_counts-predicted,axis=0)\n",
    "\n",
    "# slope, intercept, rvalue, pvalue, std_err = linregress(x, y=y)\n",
    "\n",
    "# plt.figure(\"mean_error_vs_variance\")\n",
    "# plt.title(\"Standard Deviation vs Mean Error\")\n",
    "# plt.scatter(x,y,s=.1)\n",
    "# # plt.plot(x,x*slope + intercept, 'r', label = str(np.around(rvalue,decimals=3)))\n",
    "# plt.plot([0,3],[0,3])\n",
    "# plt.plot([0,3],[0,-3])\n",
    "# plt.ylim((-1,1))\n",
    "# plt.xlabel(\"Standard Deviation\")\n",
    "# plt.ylabel(\"Mean Error\")\n",
    "# plt.legend()\n",
    "# plt.savefig(output_directory+\"mean_error_vs_variance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predicted = np.loadtxt('./predictions/combined_prediction')\n",
    "# correlations = []\n",
    "\n",
    "# for i in range(true_counts.shape[1]):\n",
    "#     correlations.append(pearsonr(true_counts[:,i],predicted[:,i])[0])\n",
    "#     if isnan(correlations[-1]):\n",
    "#         correlations[-1] = 0\n",
    "# print(len(correlations))\n",
    "\n",
    "    \n",
    "# plt.figure(\"correlation_vs_mean\",figsize=(20,4))\n",
    "# plt.title(\"Correlation of Predictions vs Expression Level\")\n",
    "# plt.scatter(correlations,np.mean(true_counts,axis=0),s=.3,c=variation(true_counts,axis=0))\n",
    "# plt.ylabel(\"Mean Expression\")\n",
    "# plt.xlabel(\"Correlation\")\n",
    "# plt.colorbar(label=\"Coefficient of Variation\")\n",
    "# plt.clim(0,10)\n",
    "# plt.savefig(output_directory+\"correlation_vs_mean_vs_cov.png\",dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations = []\n",
    "\n",
    "# for i in range(true_counts.shape[1]):\n",
    "#     correlations.append(pearsonr(true_counts[:,i],predicted[:,i])[0])\n",
    "#     if isnan(correlations[-1]):\n",
    "#         correlations[-1] = 0\n",
    "    \n",
    "# print(len(correlations))\n",
    "\n",
    "# plt.figure(\"correlation_vs_cov\")\n",
    "# plt.title(\"Correlation of features vs Coefficient of Variance\")\n",
    "# plt.xlabel(\"Coefficient of Variation\")\n",
    "# plt.ylabel(\"Correlation\")\n",
    "# plt.scatter(variation(true_counts,axis=0),correlations,s=.1,c=np.std(true_counts,axis=0))\n",
    "# plt.colorbar(label=\"Standard Deviation of Feature\")\n",
    "# plt.xlim(0,2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_mask = np.random.rand(*test_counts.flatten().shape) < (subsampling/10.0)\n",
    "\n",
    "# errors = test_counts - prediction\n",
    "\n",
    "# plt.figure(\"error_vs_true_expression\")\n",
    "# plt.title(\"Error vs True Expression\")\n",
    "# plt.scatter(test_counts.flatten()[random_mask],errors.flatten()[random_mask],s=.3,alpha=.3,c=np.tile(np.mean(test_counts,axis=0),(test_counts.shape[0],1)).flatten()[random_mask],cmap='inferno')\n",
    "# plt.xlabel(\"True Expression\")\n",
    "# plt.ylabel(\"Error\")\n",
    "# plt.colorbar(label=\"Mean expression of gene\")\n",
    "# plt.savefig(output_directory+\"error_vs_true_expression.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = prediction - test_counts\n",
    "\n",
    "# mean_cell_error = np.mean(error,axis=1)\n",
    "# mean_gene_error = np.mean(error,axis=0)\n",
    "\n",
    "# print(mean_gene_error.shape)\n",
    "# print(mean_cell_error.shape)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Distribution of Mean Feature Errors\")\n",
    "# plt.hist(mean_gene_error,bins=20)\n",
    "# plt.xlabel(\"Mean Error\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Distribution of Mean Cell Errors\")\n",
    "# plt.hist(mean_cell_error,bins=20)\n",
    "# plt.xlabel(\"Mean Error\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression_sorted_features = test_counts.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "# expression_sorted_prediction = prediction.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "\n",
    "\n",
    "# plt.figure(\"predictability\")\n",
    "# plt.title(\"Correlation of Features to Other Features, Sorted By Mean Expression\")\n",
    "# plt.imshow(np.corrcoef(expression_sorted_features.T))\n",
    "# plt.colorbar(label=\"Correlation\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression_sorted_features = test_counts.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "\n",
    "# random_mask = np.random.rand(*expression_sorted_features.flatten().shape) < subsampling\n",
    "\n",
    "\n",
    "# plt.figure(\"ranked_feature_expression\",figsize=(20,4))\n",
    "# plt.title(\"Observed Expressions For Each Feature Ranked By Mean Expression\")\n",
    "# plt.scatter(np.tile(np.arange(expression_sorted_features.shape[1]),(expression_sorted_features.shape[0],1)).flatten()[random_mask],expression_sorted_features.flatten()[random_mask],s=.3,alpha=.1, label=\"Observed Expression\")\n",
    "# # plt.scatter(np.mean(true_counts,axis=0),np.median(true_counts,axis=0),c='r',s=.5, label=\"Mean Expression\")\n",
    "# plt.xlabel(\"Feature Rank\")\n",
    "# plt.ylabel(\"Observed Expression\")\n",
    "# plt.ylim((0,10))\n",
    "# plt.legend()\n",
    "# plt.savefig(output_directory+\"rank_ordered_expresssion.png\")\n",
    "\n",
    "# for cluster in forest.sample_clusters:\n",
    "#     cluster_samples = cluster.samples\n",
    "#     cluster_counts = forest.output[cluster_samples].T[np.argsort(np.mean(forest.output,axis=0))].T\n",
    "#     print(cluster_counts.shape)\n",
    "#     plt.figure(figsize=(20,4))\n",
    "#     plt.scatter(np.tile(np.arange(cluster_counts.shape[1]),(cluster_counts.shape[0],1)).flatten(),cluster_counts.flatten(),s=.3,alpha=.1)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agglomerated_features = test_counts.T[feature_sort].T\n",
    "# random_mask = np.random.rand(*agglomerated_features.flatten().shape) < subsampling\n",
    "\n",
    "# plt.figure(\"ranked_feature_expression\",figsize=(20,4))\n",
    "# plt.title(\"Observed Expressions For Each Feature Ranked By Mean Expression\")\n",
    "# plt.scatter(np.tile(np.arange(agglomerated_features.shape[1]),(agglomerated_features.shape[0],1)).flatten()[random_mask],agglomerated_features.flatten()[random_mask],s=.3,alpha=.1, label=\"Observed Expression\")\n",
    "# plt.xlabel(\"Feature Rank\")\n",
    "# plt.ylabel(\"Observed Expression\")\n",
    "# plt.ylim((0,10))\n",
    "# plt.legend()\n",
    "# plt.savefig(output_directory+\"rank_ordered_expresssion.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quick_hetorskedasticity(feature):\n",
    "#     sorted_feature = sorted(feature)\n",
    "#     first = sorted_feature[:int(len(sorted_feature)/2)]\n",
    "#     second = sorted_feature[int(len(sorted_feature)/2):]\n",
    "#     fv = np.var(first)\n",
    "#     sv = np.var(second)\n",
    "#     return fv,sv\n",
    "\n",
    "# expression_sorted_features.shape\n",
    "\n",
    "# # random_mask = np.random.rand(*expression_sorted_features.flatten().shape) < subsampling\n",
    "\n",
    "# heteroskedasticity = [quick_hetorskedasticity(feature)[0]/quick_hetorskedasticity(feature)[1] for feature in expression_sorted_features.T]\n",
    "# var1 = [quick_hetorskedasticity(feature)[0] for feature in expression_sorted_features.T]\n",
    "# var2 = [quick_hetorskedasticity(feature)[1] for feature in expression_sorted_features.T]\n",
    "\n",
    "# print(var1)\n",
    "# print(var2)\n",
    "\n",
    "# # print(len(heteroskedasticity))\n",
    "\n",
    "# # print(heteroskedasticity)\n",
    "\n",
    "# plt.figure(\"heteroskedasticity\",figsize=(20,4))\n",
    "# plt.title(\"Heteroskedasticity\",fontsize=20)\n",
    "# plt.scatter(np.arange(0,len(var1)),var1,s=4,alpha=1,c='r',label=\"First\")\n",
    "# plt.scatter(np.arange(0,len(var2)),var2,s=4,alpha=1,c='b',label=\"Second\")\n",
    "# # plt.scatter(np.mean(true_counts,axis=0),np.median(true_counts,axis=0),c='r',s=.5, label=\"Mean Expression\")\n",
    "# plt.xlabel(\"Feature Rank\",fontsize=15)\n",
    "# plt.ylabel(\"Ratio\\n Var for f greater than median vs less\",fontsize=12)\n",
    "# plt.legend()\n",
    "# plt.savefig(output_directory+\"heterskedasticity.png\")\n",
    "\n",
    "# plt.figure(\"heteroskedasticity2\",figsize=(20,4))\n",
    "# plt.title(\"Heteroskedasticity\",fontsize=20)\n",
    "# plt.scatter(np.arange(0,len(heteroskedasticity)),heteroskedasticity,s=4,alpha=1,c='b')\n",
    "# plt.xlabel(\"Feature Rank\",fontsize=15)\n",
    "# plt.ylabel(\"Ratio\\n Var for f greater than median vs less\",fontsize=12)\n",
    "# plt.savefig(output_directory+\"heterskedasticity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# for j in range(10):\n",
    "#     i = random.randint(1,true_counts.shape[0])\n",
    "#     plt.figure('cell_multiplex' + str(i))\n",
    "#     plt.scatter(np.arange(expression_sorted_features.shape[1]),expression_sorted_features[i],s=.1)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(10):\n",
    "#     i = random.randint(1,expression_sorted_features.shape[1])\n",
    "#     plt.figure(\"feature_dist_multiplex\" + str(i))\n",
    "#     plt.hist(expression_sorted_features[:,i],bins=50,log=True)\n",
    "#     plt.show()\n",
    "\n",
    "# # deciles = np.zeros((20,expression_sorted_features.shape[1]))\n",
    "# # derivatives = np.zeros((19,expression_sorted_features.shape[1]))\n",
    "# # for i,feature in enumerate(expression_sorted_features.T):\n",
    "# #     bins,edges = np.histogram(feature,bins=20,range=(np.min(feature),np.max(feature)))\n",
    "# # #     print(bins)\n",
    "# # #     print(edges)\n",
    "# # #     print(np.array([y-x for x,y in zip(bins,bins[1:])]))\n",
    "# #     deciles[:,i] = bins\n",
    "# #     derivatives[:,i] = np.array([y-x for x,y in zip(bins,bins[1:])])\n",
    "\n",
    "# # plt.figure(figsize=(20,4))\n",
    "# # plt.imshow(deciles,aspect='auto')\n",
    "# # plt.show()\n",
    "\n",
    "# # plt.figure(figsize=(20,4))\n",
    "# # plt.imshow(derivatives,aspect='auto')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print true_counts[:10,:10]\n",
    "\n",
    "# expression_sorted_features = test_counts.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "\n",
    "# expression_sorted_prediction = prediction.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "\n",
    "# random_mask = np.random.rand(*expression_sorted_features.flatten().shape) < (subsampling)\n",
    "\n",
    "# plt.figure(\"ranked_feature_predicted\",figsize=(20,4))\n",
    "# plt.title(\"Predicted Values By Mean Expression Ranking\")\n",
    "# plt.scatter(np.tile(np.arange(expression_sorted_features.shape[1]),(expression_sorted_features.shape[0],1)).flatten()[random_mask],expression_sorted_prediction.flatten()[random_mask],s=.05,alpha=.3,label=\"Expression\",c=np.abs(expression_sorted_prediction-expression_sorted_features).flatten()[random_mask],cmap='plasma')\n",
    "# # plt.scatter(np.arange(expression_sorted_features.shape[1]),np.median(expression_sorted_features,axis=0),c='m',s=.5,label=\"Medians\")\n",
    "# # plt.scatter(np.arange(expression_sorted_features.shape[1]),np.mean(expression_sorted_features,axis=0),c='c',s=.5,label=\"Means\")\n",
    "# plt.legend()\n",
    "# plt.colorbar(label=\"Absolute Value of Error\")\n",
    "# plt.clim(0,10)\n",
    "# plt.savefig(output_directory+\"rank_ordered_predicted.png\",dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_mask = np.random.rand(*expression_sorted_features.flatten().shape) < subsampling\n",
    "\n",
    "# plt.figure(\"error_scatter_ranked\", figsize=(20,4))\n",
    "# plt.title(\"Observed Error By Mean Expression Ranking\")\n",
    "# plt.scatter(np.tile(np.arange(expression_sorted_features.shape[1]),(expression_sorted_features.shape[0],1)).flatten()[random_mask],(expression_sorted_features - expression_sorted_prediction).flatten()[random_mask],alpha=.1,s=.1)\n",
    "# plt.xlabel(\"Rank\")\n",
    "# plt.ylabel(\"Predicted Expression\")\n",
    "# plt.savefig(output_directory+\"rank_ordered_error.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations = []\n",
    "\n",
    "# for i in range(test_counts.shape[1]):\n",
    "    \n",
    "#     correlations.append(pearsonr(test_counts[:,i],prediction[:,i])[0])\n",
    "#     if isnan(correlations[-1]):\n",
    "#         correlations[-1] = 0\n",
    "        \n",
    "# print(len(correlations))\n",
    "# print(test_counts.shape)\n",
    "        \n",
    "# plt.figure(\"correlation_vs_mean\",figsize=(20,4))\n",
    "# plt.title(\"Correlation of Predictions per Expression Ranked Feature\")\n",
    "# plt.scatter(np.arange(len(correlations)),np.array(correlations)[np.argsort(np.mean(test_counts,axis=0))],s=.5)\n",
    "# plt.xlabel(\"Feature Mean Expression Rank\")\n",
    "# plt.ylabel(\"Prediction Correlation\")\n",
    "# plt.savefig(output_directory+\"ranked_correlation.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    " \n",
    "# j = 0\n",
    "\n",
    "# while j < 10:\n",
    "#     i = random.randint(1,expression_sorted_features.shape[1])\n",
    "#     if pearsonr(expression_sorted_features[:,i],expression_sorted_prediction[:,i])[0] < .5:\n",
    "#         continue\n",
    "#     plt.figure('feature_pred_multiplex' + str(i))\n",
    "#     plt.gca().axis('equal')\n",
    "#     plt.title(\"Mean Expresion: \" + str(np.mean(expression_sorted_features[:,i])) + \" Corr: \" + str(pearsonr(expression_sorted_features[:,i],expression_sorted_prediction[:,i])[0]))\n",
    "#     plt.scatter(expression_sorted_features[:,i],expression_sorted_prediction[:,i],s=1)\n",
    "#     plt.xlabel(\"True Expression\")\n",
    "#     plt.ylabel(\"Predicted Expression\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations = []\n",
    "\n",
    "# for i in range(expression_sorted_features.shape[1]):\n",
    "    \n",
    "#     correlations.append(pearsonr(expression_sorted_features[:,i],expression_sorted_prediction[:,i])[0])\n",
    "#     if isnan(correlations[-1]):\n",
    "#         correlations[-1] = 0\n",
    "    \n",
    "# print(len(correlations))\n",
    "# print(correlations[:10])\n",
    "# print(np.arange(.05,1,.05))\n",
    "    \n",
    "# plt.figure(\"correlation_histogram\")\n",
    "# plt.title(\"Distribution of Feature Correlations\")\n",
    "# plt.hist(correlations,bins=np.arange(0,1,.05))\n",
    "# plt.savefig(output_directory+\"correlation_distributions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearsonr(true_counts.flatten(),imputed_gradient.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Median Random Forest Prediction\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_basic_forest,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/basic_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print np.var(predicted,axis=0).shape\n",
    "\n",
    "# plt.figure(\"means\")\n",
    "# plt.title(\"Distribution of Means\")\n",
    "# plt.hist(np.mean(true_counts,axis=0),bins=np.arange(20),alpha=.1,label=\"Data\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"stds\")\n",
    "# plt.title(\"Distribution of Standard Deviations\")\n",
    "# plt.hist(np.std(true_counts,axis=0), bins=np.arange(20),alpha=.1,label=\"Data\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"naive_mae\")\n",
    "# plt.title(\"Distribution of Means of Error\")\n",
    "# plt.hist(np.mean(np.abs(true_counts - predicted), axis=0),bins=np.arange(20),alpha=.1,label=\"Error\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"naive_mse\")\n",
    "# plt.title(\"Distribution of MSE per feature\")\n",
    "# plt.hist(np.mean((true_counts - predicted)**2, axis=0),bins=np.arange(20),alpha=.1,label=\"Error\")\n",
    "# plt.show()\n",
    "\n",
    "# np.random.shuffle(predicted)\n",
    "# plt.figure(\"mae_shuffled\")\n",
    "# plt.title(\"Distribution of Means of Error (Shuffled)\")\n",
    "# plt.hist(np.var(np.abs(true_counts - predicted),axis=0),bins=np.arange(20),alpha=.1,label=\"Shuffled\")\n",
    "# # plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Gradient Random Forest Prediction\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_gradient,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/gradient_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print np.sum(true_counts,axis=1).shape\n",
    "\n",
    "# plt.figure(\"cell_histograms\")\n",
    "# plt.title(\"Frequency of Total Cell Counts\")\n",
    "# plt.hist(np.sum(true_counts,axis=1))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power = 2\n",
    "\n",
    "# print(np.sum(true_counts,axis=1).shape)\n",
    "\n",
    "# plt.figure(\"cell_histograms\")\n",
    "# plt.title(\"Frequency of Total Cell Counts (Log)\")\n",
    "# plt.hist(np.sum(np.power(true_counts,power),axis=1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"KNN Imputation\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_knn,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/knn_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Soft Imputation Prediction\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_soft,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/soft_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Sklearn Random Forest Prediction\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_builtin,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/sklearn_rf_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_iris = np.loadtxt('./testing/iris.trunc')\n",
    "# dropped_iris = np.loadtxt('./testing/iris.drop')\n",
    "# nan_iris = dropped_iris.copy()\n",
    "# nan_iris[nan_iris == 0] = np.nan\n",
    "\n",
    "# forest_prediction = np.loadtxt('./iris_test/run.prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft_iris = fi.SoftImpute().complete(nan_iris)\n",
    "\n",
    "# knn_iris = fi.KNN(k=15).complete(nan_iris)\n",
    "\n",
    "# factorized_iris = fi.MatrixFactorization().complete(nan_iris)\n",
    "\n",
    "# iterative_iris = fi.IterativeSVD(rank=5).complete(nan_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# guess_mask = dropped_iris.flatten() == 0\n",
    "\n",
    "# truth = true_iris.flatten()[guess_mask] \n",
    "\n",
    "# print \"Pearson correlations of Soft, KNN, Factorized, and Forest\"\n",
    "# print pearsonr(soft_iris.flatten()[guess_mask],truth)\n",
    "# print pearsonr(knn_iris.flatten()[guess_mask],truth)\n",
    "# print pearsonr(factorized_iris.flatten()[guess_mask],truth)\n",
    "# print pearsonr(forest_prediction.flatten()[guess_mask],truth)\n",
    "\n",
    "# print \"MSE of Soft, KNN, Factorized, and Forest\"\n",
    "# print np.mean(((soft_iris.flatten()[guess_mask] - truth) ** 2))\n",
    "# print np.mean(((knn_iris.flatten()[guess_mask] - truth) ** 2))\n",
    "# print np.mean(((factorized_iris.flatten()[guess_mask] - truth) ** 2))\n",
    "# print np.mean(((forest_prediction.flatten()[guess_mask] - truth) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(\"soft_iris\")\n",
    "# plt.title(\"Soft Imptuation of the Iris Dataset\")\n",
    "# plt.xlabel(\"Imputed\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.scatter(soft_iris.flatten()[guess_mask],true_iris.flatten()[guess_mask],s=1)\n",
    "# plt.plot([0,8],[0,8])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"figures/soft_iris_scatter.png\")\n",
    "\n",
    "# plt.figure(\"knn_iris\")\n",
    "# plt.title(\"KNN Imptuation of the Iris Dataset\")\n",
    "# plt.xlabel(\"Imputed\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.scatter(knn_iris.flatten()[guess_mask],true_iris.flatten()[guess_mask],s=1)\n",
    "# plt.plot([0,8],[0,8])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"figures/knn_iris_scatter.png\")\n",
    "\n",
    "# plt.figure(\"factorized_iris\")\n",
    "# plt.title(\"Matrix Factorization Imptuation of the Iris Dataset\")\n",
    "# plt.xlabel(\"Imputed\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.scatter(factorized_iris.flatten()[guess_mask],true_iris.flatten()[guess_mask],s=1)\n",
    "# plt.plot([0,8],[0,8])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"figures/factorized_iris_scatter.png\")\n",
    "\n",
    "# plt.figure(\"forest_iris\")\n",
    "# plt.title(\"Median Forest (Non-Gradient) Imptuation of the Iris Dataset\")\n",
    "# plt.xlabel(\"Imputed\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.scatter(forest_prediction.flatten()[guess_mask],true_iris.flatten()[guess_mask],s=1)\n",
    "# plt.plot([0,8],[0,8])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"figures/forest_iris_scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_counts = held_out_counts.copy()\n",
    "# nan_counts[nan_counts == 0] = np.nan\n",
    "\n",
    "# soft_blood = fi.SoftImpute().complete(nan_counts)\n",
    "\n",
    "# knn_blood = fi.KNN(k=15).complete(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = mask.astype(dtype=bool)\n",
    "# # mask = np.logical_and(true_counts != 0, mask)\n",
    "\n",
    "# truth = true_counts[mask].flatten()\n",
    "# pred_basic_forest = imputed_basic[mask].flatten()\n",
    "# pred_gradient = imputed_gradient[mask].flatten()\n",
    "\n",
    "# pred_builtin = imputed_builtin[mask].flatten()\n",
    "\n",
    "# pred_knn = knn_blood[mask].flatten()\n",
    "# pred_soft = soft_blood[mask].flatten()\n",
    "\n",
    "# print \"Pearson of random, gradient, builtin, knn, and soft\"\n",
    "\n",
    "# print pearsonr(truth,pred_basic_forest)\n",
    "# print pearsonr(truth,pred_gradient)\n",
    "# print pearsonr(truth,pred_builtin)\n",
    "# print pearsonr(truth,pred_knn)\n",
    "# print pearsonr(truth,pred_soft)\n",
    "\n",
    "# print \"MSE of random, gradient, builtin, knn, and soft\"\n",
    "\n",
    "# print np.mean((pred_basic_forest - truth) ** 2)\n",
    "# print np.mean((pred_gradient - truth) ** 2)\n",
    "# print np.mean((pred_builtin - truth) ** 2)\n",
    "# print np.mean((pred_knn - truth) ** 2)\n",
    "# print np.mean((pred_soft - truth) ** 2)\n",
    "\n",
    "# print \"Mean absolute error\"\n",
    "# print np.mean(np.abs(pred_basic_forest - truth))\n",
    "# print np.mean(np.abs(pred_gradient - truth))\n",
    "# print np.mean(np.abs(pred_builtin - truth))\n",
    "# print np.mean(np.abs(pred_knn - truth))\n",
    "# print np.mean(np.abs(pred_soft - truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# for i in range(10):\n",
    "\n",
    "#     print \"Selecting features\"\n",
    "    \n",
    "#     in_features = np.random.rand(true_counts.shape[1]) > .7\n",
    "#     out_features = np.logical_not(in_features)\n",
    "\n",
    "#     training_samples = np.random.rand(true_counts.shape[0]) > .3\n",
    "#     testing_samples = np.logical_not(training_samples)\n",
    "\n",
    "#     training_in = true_counts[training_samples].T[in_features].T\n",
    "#     training_out = true_counts[training_samples].T[out_features].T\n",
    "\n",
    "#     testing_in = true_counts[testing_samples].T[in_features].T\n",
    "#     testing_out = true_counts[testing_samples].T[out_features].T\n",
    "\n",
    "#     print \"Initializing feature\"\n",
    "    \n",
    "#     forest = GradientBoostingRegressor()\n",
    "\n",
    "#     print \"Fitting\"\n",
    "    \n",
    "#     forest.fit(training_in,training_out)\n",
    "    \n",
    "#     print \"Predicting\"\n",
    "    \n",
    "#     prediction = forest.predict(testing_in)\n",
    "\n",
    "#     print np.sum(in_features)\n",
    "#     print np.sum(out_features)\n",
    "#     print np.sum(training_samples)\n",
    "#     print np.sum(testing_samples)\n",
    "    \n",
    "#     print prediction.shape\n",
    "#     print testing_out.shape\n",
    "    \n",
    "#     print \"Pearson R\"\n",
    "#     print pearsonr(testing_out.flatten(),prediction.flatten())\n",
    "    \n",
    "#     print \"MSE\"\n",
    "#     print np.mean((prediction.flatten() - testing_out.flatten()) ** 2)\n",
    "    \n",
    "#     print \"MAE\"\n",
    "#     print np.mean(np.abs(prediction.flatten() - testing_out.flatten()))\n",
    "\n",
    "    \n",
    "# print \"Fitting done\"\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# print start_time - end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# for i in range(10):\n",
    "\n",
    "#     print \"Selecting features\"\n",
    "    \n",
    "#     in_features = np.random.rand(true_counts.shape[1]) > .7\n",
    "#     out_features = np.logical_not(in_features)\n",
    "\n",
    "#     training_samples = np.random.rand(true_counts.shape[0]) > .3\n",
    "#     testing_samples = np.logical_not(training_samples)\n",
    "\n",
    "#     training_in = true_counts[training_samples].T[in_features].T\n",
    "#     training_out = true_counts[training_samples].T[out_features].T\n",
    "\n",
    "#     testing_in = true_counts[testing_samples].T[in_features].T\n",
    "#     testing_out = true_counts[testing_samples].T[out_features].T\n",
    "\n",
    "#     print \"Initializing feature\"\n",
    "    \n",
    "#     forest = RandomForestRegressor(n_estimators=100,min_samples_split=50,n_jobs=int(10),max_features=400)\n",
    "\n",
    "#     print \"Fitting\"\n",
    "    \n",
    "#     forest.fit(training_in,training_out)\n",
    "    \n",
    "#     print \"Predicting\"\n",
    "    \n",
    "#     prediction = forest.predict(testing_in)\n",
    "\n",
    "#     print np.sum(in_features)\n",
    "#     print np.sum(out_features)\n",
    "#     print np.sum(training_samples)\n",
    "#     print np.sum(testing_samples)\n",
    "    \n",
    "#     print prediction.shape\n",
    "#     print testing_out.shape\n",
    "    \n",
    "#     print \"Pearson R\"\n",
    "#     print pearsonr(testing_out.flatten(),prediction.flatten())\n",
    "    \n",
    "#     print \"MSE\"\n",
    "#     print np.mean((prediction.flatten() - testing_out.flatten()) ** 2)\n",
    "    \n",
    "#     print \"MAE\"\n",
    "#     print np.mean(np.abs(prediction.flatten() - testing_out.flatten()))\n",
    "\n",
    "    \n",
    "# print \"Fitting done\"http://localhost:8888/notebooks/evaluate_prediction.ipynb#\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# print start_time - end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# braid = trbr.IHMM.reconstitute('./forest_vision_braid')\n",
    "# braid = trbr.IHMM(forest,beta=100,gamma=100,start_states=100,alpha_e=.5,beta_e=.5,inf_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(300):\n",
    "#     print(\"********\")\n",
    "#     print(i)\n",
    "#     print(braid.alpha)\n",
    "#     print(braid.beta)\n",
    "#     print(braid.gamma)\n",
    "#     print(len(braid.hidden_states))\n",
    "#     print(\"********\")\n",
    "#     braid.sample_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     print(\"********\")\n",
    "#     print(f\"SWEEP:{i}\")\n",
    "#     print(f\"Beta:{braid.beta}\")\n",
    "#     print(f\"Gamma:{braid.gamma}\")\n",
    "#     braid.sweep()\n",
    "#     braid.max_likelihood_sweep()\n",
    "#     if i%3 == 0:\n",
    "#         braid.max_likelihood_sweep()\n",
    "#     print(braid.oracle_transition_counts)\n",
    "#     print(braid.transition_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(np.sum(braid.state_masks,axis=1))\n",
    "# print(braid.state_sample_log_odds.shape)\n",
    "# # print(list(braid.state_sample_log_odds[1]))\n",
    "# # print(list(braid.state_raw_emission_counts[1]))\n",
    "# # print(list(enumerate(np.sum(braid.state_masks,axis=1))))\n",
    "# print(np.arange(12550)[braid.state_masks[9]])\n",
    "# ni = 8720\n",
    "# print(braid.state_log_odds_given_divergence[:,ni])\n",
    "# print(braid.state_log_odds_given_child_l[:,ni])\n",
    "# print(braid.state_log_odds_given_child_r[:,ni])\n",
    "# print(braid.state_log_odds[:,ni])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(enumerate(np.mean(braid.state_log_odds_given_divergence[:,braid.live_mask],axis=0)),key=lambda x: x[1]))\n",
    "\n",
    "# ni = 98\n",
    "# print(braid.state_log_odds_given_divergence[:,ni])\n",
    "# print(braid.state_log_odds_given_child_l[:,ni])\n",
    "# print(braid.state_log_odds_given_child_r[:,ni])\n",
    "# print(braid.state_log_odds[:,ni])\n",
    "\n",
    "# print(braid.state_log_odds[:,ni])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# braid.node_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     braid.sweep()\n",
    "#     if i%5 == 0:\n",
    "#         braid.max_likelihood_sweep()\n",
    "# list(braid.state_sample_log_odds[1])\n",
    "# np.sum(np.abs(braid.state_sample_log_odds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iftc = forest.tsne_encoding()\n",
    "# iftc = forest.tsne(override=True)\n",
    "\n",
    "# cell_id_header = np.loadtxt('/Users/boris/taylor/vision/python_prototype/raw_data/vision_sc/cell_id_header.txt',dtype='str')\n",
    "# cell_ids = np.loadtxt('/Users/boris/taylor/vision/python_prototype/raw_data/vision_sc/cell_identity.txt',dtype=bool)\n",
    "\n",
    "# mep_index = list(cell_id_header).index('MEP_narrow')\n",
    "\n",
    "# print(mep_index)\n",
    "# print(np.sum(cell_ids[:,mep_index]))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(iftc[:,0],iftc[:,1],c=cell_ids[:,mep_index])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"State Transition Frequency,0 is Root\")\n",
    "# plt.imshow(forest.split_cluster_transition_matrix(depth=4),cmap='binary')\n",
    "# plt.show()\n",
    "  \n",
    "# # print(braid.state_raw_sample_odds[1])\n",
    "# for hidden_state in range(braid.hidden_states):\n",
    "#     print(np.sum(braid.state_masks[hidden_state]))\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.title(f\"Hidden State {hidden_state}\",fontsize=20)\n",
    "#     plt.scatter(iftc[:,0],iftc[:,1],c=braid.lr_finite(hidden_state),cmap='bwr',s=.3)\n",
    "#     plt.ylim(-30,30)\n",
    "#     plt.xlim(-30,40)\n",
    "# #     plt.colorbar()\n",
    "# #     plt.scatter(iftc[:,0],iftc[:,1],c=braid.state_raw_sample_odds[hidden_state],s=1,cmap='PuOr')\n",
    "#     plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Frequency of Transitions from One Hidden State To Another\")\n",
    "# plt.imshow(braid.pad_root_transitions(braid.raw_transition_counts()).T,cmap='binary')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.plot_sample_feature_split(braid.lr_finite(14),plot_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# braid.backup('./forest_vision_braid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(7))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(8))[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(3))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(4))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(13))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(14))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(11))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(5))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(6))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(1))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(2))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in forest.node_feature_summary(braid.hidden_state_to_nodes(9)):\n",
    "#     print(f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from goatools.base import download_go_basic_obo\n",
    "# obo_fname = download_go_basic_obo()\n",
    "\n",
    "# from goatools.base import download_ncbi_associations\n",
    "# gene2go = download_ncbi_associations()\n",
    "\n",
    "\n",
    "# from goatools.obo_parser import GODag\n",
    "\n",
    "# obodag = GODag(\"go-basic.obo\")\n",
    "\n",
    "# from goatools.associations import read_ncbi_gene2go,dnld_assc\n",
    "\n",
    "# geneid2gos_mouse = read_ncbi_gene2go(\"gene2go\", taxids=[10090])\n",
    "\n",
    "# print(\"{N:,} annotated mouse genes\".format(N=len(geneid2gos_mouse)))\n",
    "\n",
    "# from goatools.go_enrichment import GOEnrichmentStudy\n",
    "# from goatools.test_data.genes_NCBI_10090_ProteinCoding import GENEID2NT as GeneID2nt_mus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goeaobj = GOEnrichmentStudy(\n",
    "#         GeneID2nt_mus.keys(), # List of mouse protein-coding genes\n",
    "#         geneid2gos_mouse, # geneid/GO associations\n",
    "#         obodag, # Ontologies\n",
    "#         propagate_counts = False,\n",
    "#         alpha = 0.05, # default significance cut-off\n",
    "#         methods = ['fdr_bh']) # defult multipletest correction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol2id = {v[5]:k for k,v in GeneID2nt_mus.items()}\n",
    "\n",
    "# def try_symbol(symbols):\n",
    "#     ids = []\n",
    "#     for symbol in symbols:\n",
    "#         if symbol in symbol2id:\n",
    "#             ids.append(symbol2id[symbol])\n",
    "#     return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gores = goeaobj.run_study(try_symbol([x[0] for x in forest.node_feature_summary(braid.hidden_state_to_nodes(13))]))\n",
    "\n",
    "# gores_filtered = sorted([r for r in gores if r.p_fdr_bh < 0.05],key=lambda r: r.p_fdr_bh)\n",
    "\n",
    "# gores_filtered = [g for g in gores_filtered if g.goterm.namespace == 'biological_process' or g.goterm.namespace == 'molecular_function']\n",
    "\n",
    "# print(gores_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gores_filtered[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [go.name for go in gores_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for term in [go.name for go in gores_filtered]:\n",
    "#     print(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_identity_str = np.loadtxt(\"../../raw_data/vision_sc/nesterowa_cell_type_membership.txt\",dtype=str)\n",
    "# cell_identity_header = np.loadtxt(\"../../raw_data/vision_sc/nesterowa_cell_type_header.txt\",dtype=str)\n",
    "# cell_identity_uid = cell_identity_str[:,0]\n",
    "# cell_identity_float = cell_identity_str.astype(dtype=float)\n",
    "# cell_identity_binary = cell_identity_float.astype(dtype=bool)\n",
    "# counts = np.loadtxt(\"../../raw_data/vision_sc/nesterowa_counts.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_identity_header\n",
    "# cell_identity_header[9:-1]\n",
    "# cell_identity = np.array([([0,] + list(np.arange(c.shape[0])[c] + 1))[-1] for c in cell_identity_binary[:,9:-1]])\n",
    "\n",
    "# cell_identity[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from matplotlib.cm import get_cmap\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# rainbow=get_cmap('rainbow')\n",
    "\n",
    "# cluster_names = [\"None\",] + list(cell_identity_header[9:-1])\n",
    "# cluster_names = np.array([cluster_names]).T\n",
    "# clusters = sorted(list(set(cell_identity)))\n",
    "# clusters = np.array([clusters]).T\n",
    "# colors = np.array([rainbow(c/len(clusters)) for c in clusters]).T.T\n",
    "\n",
    "# print(cluster_names)\n",
    "# print(clusters)\n",
    "# print(colors)\n",
    "\n",
    "# # coordinates = forest.coordinates(type='tsne',pca=True,override=False)\n",
    "# coordinates = TSNE().fit_transform(PCA(n_components=2).fit_transform(counts))\n",
    "# fig = plt.figure(figsize=(15,10))\n",
    "# scatter_ax = fig.add_axes([0,0,1,1])\n",
    "# scatter_ax.set_title(\"Mouse Hematopoietic Cells By Type, FACS\",color='w')\n",
    "# scatter_ax.scatter(coordinates[:,0],coordinates[:,1],c=cell_identity,cmap='rainbow',s=20)\n",
    "# scatter_ax.set_xticks([])\n",
    "# scatter_ax.set_yticks([])\n",
    "# table_ax = fig.add_axes([.05,.05,.1,.3])\n",
    "# table_ax.axis(\"off\")\n",
    "# table_ax.table(cellText=cluster_names,cellColours=colors,bbox=[0,0,1,1],)\n",
    "# plt.show()\n",
    "\n",
    "# colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hidden_state_sample_cluster_matrix(forest,braid):\n",
    "#     state_cluster_matrix = np.zeros((len(forest.sample_clusters),braid.hidden_states))\n",
    "#     for i,sample_cluster in enumerate(forest.sample_clusters):\n",
    "#         for j,hidden_state in enumerate(braid.state_sample_log_odds):\n",
    "#             odds_sample_x_cluster = hidden_state[sample_cluster.samples]\n",
    "#             state_cluster_matrix[i,j] = np.mean(odds_sample_x_cluster)\n",
    "#     return state_cluster_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters_x_hs = hidden_state_sample_cluster_matrix(forest,braid)\n",
    "\n",
    "# cluster_sort = np.array(dendrogram(linkage(clusters_x_hs,method='average'),no_plot=True)['leaves'])\n",
    "# hs_sort = np.argsort([np.mean([n.level for n in braid.hidden_state_to_nodes(hs)]) for hs in range(braid.hidden_states)])\n",
    "# # hs_sort = np.array(dendrogram(linkage(clusters_x_hs.T,method='average'),no_plot=True)['leaves'])\n",
    "\n",
    "# cell_cluster_mask = np.array([len(c.samples) > 40 for c in forest.sample_clusters])\n",
    "# cell_cluster_mask = cell_cluster_mask[cluster_sort]\n",
    "\n",
    "# hidden_state_mask = np.array([np.sum(hsm) > 100 for hsm in braid.state_masks[:,braid.live_mask]])\n",
    "# print(hidden_state_mask)\n",
    "# hidden_state_mask = hidden_state_mask[hs_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Fit of Cell Clusters To Hidden States\")\n",
    "# plt.imshow(clusters_x_hs[cluster_sort][cell_cluster_mask].T[hs_sort][hidden_state_mask],aspect='auto')\n",
    "# plt.ylabel(\"Hidden States\")\n",
    "# plt.xlabel(\"Cell Clusters\")\n",
    "# plt.xticks(np.arange(len(cluster_sort[cell_cluster_mask])),cluster_sort[cell_cluster_mask])\n",
    "# plt.yticks(np.arange(len(hs_sort[hidden_state_mask])),hs_sort[hidden_state_mask])\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.colors import Colormap\n",
    "# from matplotlib.cm import get_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# braids = [n.braid for n in forest.split_clusters[0].nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [b.features[0] for b in braids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.split_clusters[0].braid_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# model = PCA().fit(forest.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading_sort = np.argsort(model.components_[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(forest.output_features[loading_sort])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_x_split = np.zeros((len(forest.split_clusters),len(set(cell_identity))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(cell_x_split.shape[0]):\n",
    "#     for j in range(cell_x_split.shape[1]):\n",
    "#         print((i,j))\n",
    "#         cell_id_mask = np.array(cell_identity) == j\n",
    "#         print(np.sum(cell_id_mask))\n",
    "#         cluster_cell_scores = np.array(forest.split_clusters[i].cell_scores())\n",
    "# #         print(cluster_cell_scores)\n",
    "# #         print(cell_id_mask)\n",
    "# #         print(np.array(cluster_cell_scores)[np.array(cell_id_mask)])\n",
    "#         mean_cluster_score = np.mean(np.array(cluster_cell_scores)[np.array(cell_id_mask)])\n",
    "# #         print(mean_cluster_score)\n",
    "#         cell_x_split[i,j] = mean_cluster_score\n",
    "        \n",
    "# cluster_sort = dendrogram(linkage(cell_x_split,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# # cluster_sort = np.argsort(np.array([c.mean_level() for c in forest.split_clusters]))\n",
    "# cell_id_sort = dendrogram(linkage(cell_x_split.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(cell_x_split[cluster_sort].T[cell_id_sort],aspect='auto',cmap='binary')\n",
    "# plt.xticks(np.arange(19),cluster_sort)\n",
    "# plt.yticks(np.arange(12), np.array([\"None\",] + list(cell_identity_header[9:-1]))[cell_id_sort])\n",
    "# plt.xlabel(\"RF Clusters\")\n",
    "# plt.ylabel(\"FACS Profile\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cell_id_sort)\n",
    "# print(len(cell_id_sort))\n",
    "# print(np.array([\"None\",] + list(cell_identity_header[9:-1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.imshow(np.array([c.cell_scores() for c in forest.split_clusters]),aspect='auto',cmap='binary')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_id_global = np.zeros((len(set(cell_identity)),len(forest.samples)))\n",
    "# for i in range(len(set(cell_identity))):\n",
    "#      cell_id_global[i] = cell_identity == i\n",
    "# plt.figure()\n",
    "# plt.imshow(cell_id_global,aspect='auto',cmap='binary')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(cell_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.spli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
