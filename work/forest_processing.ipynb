{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# COLOR = 'white'\n",
    "# mpl.rcParams['text.color'] = COLOR\n",
    "# mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "# mpl.rcParams['xtick.color'] = COLOR\n",
    "# mpl.rcParams['ytick.color'] = COLOR\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "\n",
    "# import fancyimpute as fi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import variation\n",
    "from math import isnan\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import lumberjack\n",
    "import tree_reader as tr\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = np.loadtxt('/Users/boris/taylor/johnston_retina/single_cell/dmel-retina-scRNA/exploration/2018.07.19_Scanpy/log_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/johnston_retina/single_cell/dmel-retina-scRNA/exploration/2018.07.19_Scanpy/header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/work/johnston_log_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/work/johnston_header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/aging_sc/var_filtered_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/aging_sc/var_filtered_header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/fan_tendon/log_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/fan_tendon/header.txt\",dtype=str)\n",
    "\n",
    "counts = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/raw_data/vision_sc/nesterowa_counts.txt')\n",
    "header = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/raw_data/vision_sc/nesterowa_gene_header.txt',dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('nesterowa_counts.txt')\n",
    "# header = np.loadtxt('nesterowa_gene_header.txt',dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/nelmari/nc_filtered_log.txt')\n",
    "# header = np.loadtxt('/Users/boris/taylor/nelmari/gene_header_filtered.txt',dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/testing/iris.trunc')\n",
    "# header = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/testing/iris.features',dtype=str)\n",
    "\n",
    "# feature_sort = dendrogram(linkage(counts.T,metric='correlation',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# counts = counts[cell_sort].T[feature_sort].T\n",
    "# counts = counts.T[feature_sort].T\n",
    "# header = header[feature_sort]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_mask = np.random.random(counts.shape[0]) > 0\n",
    "testing_mask = np.logical_not(training_mask)\n",
    "\n",
    "training_counts = counts[training_mask]\n",
    "testing_counts = counts[testing_mask]\n",
    "\n",
    "# training_counts = counts\n",
    "# testing_counts = counts\n",
    "\n",
    "# forest = tr.Forest.reconstitute('./forest_nelmari')\n",
    "\n",
    "forest = tr.Forest.reconstitute('./forest_vision_small')\n",
    "# forest = tr.Forest.reconstitute('./forest_vision_lrg_l1')\n",
    "# forest = tr.Forest.reconstitute('./forest_vision_lrg_l2')\n",
    "\n",
    "\n",
    "# forest = tr.Forest.reconstitute('./forest_johnston_braid')\n",
    "\n",
    "# forest = tr.Forest.load(\"../testing/nelmari/\",input='../../../../../nelmari/nc_filtered_log.txt',output='../../../../../nelmari/nc_filtered_log.txt')\n",
    "# forest = tr.Forest.load(\"../testing/nesterowa_forest/\",input=\"../../work/nesterowa_counts.txt\",output=\"../../work/nesterowa_counts.txt\")\n",
    "# forest = tr.Forest.load(\"../testing/johnston_forest/\",input=\"../../work/johnston_log_counts.txt\",output=\"../../work/johnston_log_counts.txt\")\n",
    "\n",
    "# counts = sklearn.preprocessing.scale(counts)\n",
    "\n",
    "# forest = lumberjack.fit(training_counts,test_counts=testing_counts,trees=50,dispersion_mode=\"ssme\",norm=\"l1\",drop='none',sfr=1,in_feature_subsample=200,out_feature_subsample=200,sample_subsample=100,depth=5,leaves=20,header=header)\n",
    "# forest = lumberjack.fit(training_counts,test_counts=testing_counts,trees=100,dispersion_mode=\"ssme\",norm=\"l2\",lrg_mem=True,drop='none',sfr=1,in_feature_subsample=1000,out_feature_subsample=1000,sample_subsample=200,depth=5,leaves=20,header=header)\n",
    "\n",
    "# forest.weigh_leaves()\n",
    "\n",
    "training_counts = forest.output\n",
    "testing_counts = forest.test\n",
    "\n",
    "# predicted = forest.predict_matrix(testing_counts)\n",
    "\n",
    "# true_counts = testing_counts\n",
    "\n",
    "subsampling = 1\n",
    "\n",
    "# mask = np.loadtxt('./testing/holdout_mask_counts.txt')\n",
    "\n",
    "# held_out_counts = np.loadtxt('./testing/held_out_counts.txt')\n",
    "\n",
    "#2 trees at 2:17\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.backup('./forest_johnston_ihmm')\n",
    "# forest.backup('./forest_johnston_ssme')\n",
    "# forest.backup('./forest_johnston_flat_sme')\n",
    "# forest.backup('./forest_johnston_var')\n",
    "# forest.backup('./forest_fan_ssme')\n",
    "\n",
    "# forest.backup('./forest_johnston_braid')\n",
    "# forest.backup('./forest_nelmari')\n",
    "\n",
    "# forest.backup('./forest_vision_small')\n",
    "# forest.backup('./forest_vision_l1')\n",
    "# forest.backup('./forest_vision_l2')\n",
    "# forest.backup('./forest_vision_lrg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_clusters()\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "\n",
    "feature_sort = dendrogram(linkage(counts.T,metric='correlation',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "counts = forest.output\n",
    "\n",
    "encoding = forest.node_sample_encoding(forest.leaves())\n",
    "print(encoding.shape)\n",
    "\n",
    "print(np.sum(np.sum(encoding,axis=1) == 0))\n",
    "cell_sort = dendrogram(linkage(encoding,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "leaf_sort = dendrogram(linkage(encoding.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# feature_sort = dendrogram(linkage(forest.output.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# feature_sort = np.argsort(np.var(forest.output,axis=0))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "# plt.imshow(encoding,aspect='auto',cmap='binary')\n",
    "plt.imshow(encoding[cell_sort].T[leaf_sort].T,aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print(np.sum(np.isnan(encoding).flatten()))\n",
    "\n",
    "cell_clusterings = forest.cluster_samples_encoding(distance='cos',k=10,steps=50,override=False,verbose=True)\n",
    "# cell_clusterings = forest.cluster_samples_simple(pca=True,subsample=1400,distance='cos',k=10,steps=50,override=True,verbose=True)\n",
    "leaf_clusterings = forest.cluster_leaf_samples(distance='cos',k=10,steps=50,override=False,verbose=True)\n",
    "\n",
    "cell_order = np.argsort(cell_clusterings)\n",
    "leaf_order = np.argsort(leaf_clusterings)\n",
    "\n",
    "# clustered_counts = forest.output[cell_order].T[feature_sort].T\n",
    "clustered_counts = counts[cell_order].T[feature_sort].T\n",
    "clustered_encoding = encoding[cell_order].T[leaf_order].T\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"Cell x Gene Expression, Forest Clustering\",fontsize=20)\n",
    "plt.imshow(clustered_counts,aspect='auto')\n",
    "plt.xlabel(\"Genes\",fontsize=15)\n",
    "plt.ylabel(\"Cells\",fontsize=15)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"Cell x Node Organization, Forest Clustering\",fontsize=20)\n",
    "plt.imshow(clustered_encoding,aspect='auto',cmap='binary')\n",
    "plt.xlabel(\"Leaves\",fontsize=15)\n",
    "plt.ylabel(\"Cells\",fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "print(\"===================\")\n",
    "\n",
    "for cluster in forest.sample_clusters:\n",
    "    print(len(cluster.samples))\n",
    "\n",
    "print(\"===================\")\n",
    "\n",
    "for cluster in forest.leaf_clusters:\n",
    "    print(len(cluster.nodes))\n",
    "\n",
    "print(\"===================\")\n",
    "print(\"===================\")\n",
    "print(\"===================\")\n",
    "print(len(forest.sample_clusters))\n",
    "print(len(forest.leaf_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.coordinates(override=False)\n",
    "# forest.tsne_encoding(override=True)\n",
    "# forest.plot_split_clusters()\n",
    "\n",
    "# feature = \"Cd34\"\n",
    "# coordinates = forest.coordinates(override=False,no_plot=True,pca=True)\n",
    "# fi = forest.truth_dictionary.feature_dictionary[feature]\n",
    "# plt.figure()\n",
    "# plt.title(f\"Expression of {feature}\")\n",
    "# plt.scatter(coordinates[:,0],coordinates[:,1],c=forest.output[:,fi],s=10)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#########################################################\n",
    "#########################################################\n",
    "##################                     ##################\n",
    "##################   ##   ##   ####    ##################\n",
    "##################    ## ##   ##  ##   ##################\n",
    "##################     ###    ##  ##   ##################\n",
    "##################     ##     ##  ##   ##################\n",
    "##################    ##       ####    ##################\n",
    "##################                     ##################\n",
    "#########################################################\n",
    "#########################################################\n",
    "#########################################################\n",
    "\n",
    "\n",
    "forest.reset_clusters()\n",
    "forest.interpret_splits(depth=4,k=20,mode='sample',steps=50,metric='jaccard',distance='cos',optimization=\"max\",pca=False,override=True,verbose=True)\n",
    "# forest.interpret_splits(depth=5,k=10,subsample=5500,mode='gain',steps=50,distance='cos',override=False,verbose=True)\n",
    "# split_order = np.argsort(forest.split_labels)\n",
    "# print(np.sum(forest.split_labels < 7))\n",
    "# print(np.sum(forest.split_labels < 8))\n",
    "# print(np.sum(forest.split_labels < 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = forest.most_likely_tree(depth=5)\n",
    "# tree\n",
    "\n",
    "tree = forest.maximum_spanning_tree(depth=4)\n",
    "tree\n",
    "\n",
    "# transitions = forest.split_cluster_transition_matrix()\n",
    "# transitions[:,88]\n",
    "\n",
    "forest.likely_tree = forest.maximum_tree\n",
    "\n",
    "tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.cluster_samples_encoding(k=20,steps=50,override=True,verbose=True)\n",
    "# forest.cluster_samples_simple(pca=True,k=20,steps=50,override=True,verbose=True)\n",
    "forest.plot_cell_clusters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# tc = TSNE().fit_transform(forest.counts)\n",
    "\n",
    "\n",
    "# tc = forest.tsne(pca=True,override=False,no_plot=True)\n",
    "\n",
    "# tc = PCA(n_components=2).fit_transform(forest.output)\n",
    "\n",
    "tc = forest.coordinates(no_plot=True)\n",
    "\n",
    "for split_cluster in forest.split_clusters:\n",
    "    print(split_cluster.id)\n",
    "    try:\n",
    "        print(sorted(list(split_cluster.braid_features().items()),key=lambda x:x[1])[::-1])\n",
    "#         print(list(split_cluster.braid_features().items()))\n",
    "    except:\n",
    "        pass\n",
    "    split_cluster.plot_cell_counts()\n",
    "\n",
    "    sister_color = split_cluster.sister_scores()\n",
    "\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    plt.title(\"Sister Split\")\n",
    "    plt.scatter(tc[:,0],tc[:,1],c=sister_color,cmap='bwr',vmin=max(sister_color)*-1)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.plot_manifold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_identity_str = np.loadtxt(\"../../raw_data/vision_sc/nesterowa_cell_type_membership.txt\",dtype=str)\n",
    "cell_identity_header = np.loadtxt(\"../../raw_data/vision_sc/nesterowa_cell_type_header.txt\",dtype=str)\n",
    "cell_identity_uid = cell_identity_str[:,0]\n",
    "cell_identity_float = cell_identity_str.astype(dtype=float)\n",
    "cell_identity_binary = cell_identity_float.astype(dtype=bool)\n",
    "counts = np.loadtxt(\"../../raw_data/vision_sc/nesterowa_counts.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_identity_header\n",
    "cell_identity_header[9:-1]\n",
    "cell_identity = np.array([([0,] + list(np.arange(c.shape[0])[c] + 1))[-1] for c in cell_identity_binary[:,9:-1]])\n",
    "\n",
    "cell_identity[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_mutual_information(p1,p2):\n",
    "    p1 = p1.astype(dtype=float)\n",
    "    p2 = p2.astype(dtype=float)\n",
    "    population = p1.shape[1]\n",
    "    intersections = np.dot(p1,p2.T)\n",
    "    partition_size_products = np.outer(np.sum(p1,axis=1),np.sum(p2,axis=1))\n",
    "    log_term = np.log(intersections) - np.log(partition_size_products) + np.log(population)\n",
    "    log_term[np.logical_not(np.isfinite(log_term))] = 0\n",
    "    mutual_information_matrix = (intersections / population) * log_term\n",
    "    return mutual_information_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa = [0,0,0,1,1,1,0,1]\n",
    "# pb = [0,1,1,0,1,1,0,0]\n",
    "pa = [0,0,0,1,1,1,0,1]\n",
    "paa = [[0,0,0,1,1,1,0,1],[1,1,1,0,0,0,1,0]]\n",
    "pb = [1,0,0,1,1,1,0,1]\n",
    "pbb = [[1,0,0,1,1,1,0,1],[0,1,1,0,0,0,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38039566584857787"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_info_score(pa,pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7745966692414834, 0.024008196755730942)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(pa,pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47000363  0.        ]\n",
      " [-0.91629073  0.69314718]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boris/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "mim = partition_mutual_information(np.array(paa),np.array(pbb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38039566584857776"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
